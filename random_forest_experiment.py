#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TH·ª∞C NGHI·ªÜM SO S√ÅNH RANDOM FOREST V√Ä NAIVE BAYES
V·ªõi nhi·ªÅu datasets v√† k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω n√¢ng cao

Author: Student
Date: 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (classification_report, confusion_matrix, 
                           accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve)
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, RFE
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import warnings
warnings.filterwarnings('ignore')

# Thi·∫øt l·∫≠p font cho ti·∫øng Vi·ªát
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.style.use('seaborn-v0_8')

class AdvancedDataMiningExperiment:
    """
    Class th·ª±c hi·ªán th√≠ nghi·ªám khai ph√° d·ªØ li·ªáu n√¢ng cao v·ªõi nhi·ªÅu datasets
    
    M·ª•c ƒë√≠ch: So s√°nh Random Forest v√† Naive Bayes tr√™n nhi·ªÅu lo·∫°i d·ªØ li·ªáu kh√°c nhau
    v·ªõi c√°c k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω n√¢ng cao
    """
    
    def __init__(self):
        """
        Kh·ªüi t·∫°o experiment
        - results: L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh (accuracy, precision, recall, f1, auc)
        - datasets: L∆∞u d·ªØ li·ªáu th√¥ ƒë√£ load
        - feature_importance: L∆∞u ƒë·ªô quan tr·ªçng c·ªßa features (t·ª´ Random Forest)
        """
        self.results = {}
        self.datasets = {}
        self.feature_importance = {}
        
    def load_datasets(self):
        """B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu - T·∫£i t·∫•t c·∫£ datasets"""
        print("="*80)
        print("B∆Ø·ªöC 1: THU TH·∫¨P D·ªÆ LI·ªÜU")
        print("="*80)
        
        datasets_config = {
            'Wine': {
                'path': 'datasets/winequality-red.csv', #ƒê·ª©c Anh
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'Diabetes': {
                'path': 'datasets/diabetes.csv', #Huy·ªÅn
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'HeartDisease': {
                'path': 'datasets/heart_disease_uci.csv', #ƒê·ª©c Anh
                'encoding': 'utf-8',
                'type': 'mixed'
            },
            'Adult': {
                'path': 'datasets/adult.csv', #H√†
                'encoding': 'utf-8',
                'type': 'mixed'
            },
            'Mushroom': {
                'path': 'datasets/mushrooms.csv', #Tr·ªçng
                'encoding': 'utf-8',
                'type': 'categorical'
            },
            'Sonar': {
                'path': 'datasets/sonar-all-data.csv', #Tr·ªçng
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'CreditCard': {
                'path': 'datasets/creditcard.csv', #H√†
                'encoding': 'utf-8',
                'type': 'numeric'
            }
        }
        
        successful_loads = 0
        
        for name, config in datasets_config.items():
            try:
                print(f"\nüìä ƒêang t·∫£i {name} Dataset...")
                df = pd.read_csv(config['path'], encoding=config['encoding'])
                
                self.datasets[name] = {
                    'data': df,
                    'type': config['type'],
                    'shape': df.shape
                }
                
                print(f"   ‚úÖ {name}: {df.shape[0]} m·∫´u, {df.shape[1]} c·ªôt")
                successful_loads += 1
                
            except Exception as e:
                print(f"   ‚ùå L·ªói t·∫£i {name}: {e}")
            
        print(f"\n‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {successful_loads}/{len(datasets_config)} datasets")
        return successful_loads > 0
    
    def explore_data(self):
        """B∆∞·ªõc 2: Kh√°m ph√° d·ªØ li·ªáu (EDA) v·ªõi ph√¢n t√≠ch chi ti·∫øt"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 2: KH√ÅM PH√Å D·ªÆ LI·ªÜU (EDA)")
        print("="*80)
        
        for name, dataset_info in self.datasets.items():
            df = dataset_info['data']
            print(f"\n{'='*60}")
            print(f"üìä {name.upper()} DATASET")
            print(f"{'='*60}")
            print(f"K√≠ch th∆∞·ªõc: {df.shape}")
            print(f"Lo·∫°i d·ªØ li·ªáu: {dataset_info['type']}")
            print(f"\nTh√¥ng tin c·ªôt:")
            print(df.dtypes)
            print(f"\nGi√° tr·ªã null:")
            print(df.isnull().sum())
            print(f"\nTh·ªëng k√™ m√¥ t·∫£:")
            print(df.describe())
        
        # Visualization
        self.visualize_eda()
    
    def visualize_eda(self):
        """V·∫Ω bi·ªÉu ƒë·ªì kh√°m ph√° d·ªØ li·ªáu cho t·∫•t c·∫£ datasets"""
        num_datasets = len(self.datasets)
        fig, axes = plt.subplots(num_datasets, 3, figsize=(20, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('KH√ÅM PH√Å D·ªÆ LI·ªÜU - T·∫§T C·∫¢ DATASETS', fontsize=18, fontweight='bold', y=0.995)
        
        for idx, (name, dataset_info) in enumerate(self.datasets.items()):
            df = dataset_info['data']
            
            # Subplot 1: Distribution of target
            target_col = self._get_target_column(name, df)
            if target_col:
                target_counts = df[target_col].value_counts()
                axes[idx, 0].bar(range(len(target_counts)), target_counts.values, color='steelblue', alpha=0.7)
                axes[idx, 0].set_title(f'{name}: Ph√¢n b·ªë Target', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Class', fontsize=9)
                axes[idx, 0].set_ylabel('S·ªë l∆∞·ª£ng', fontsize=9)
                axes[idx, 0].tick_params(labelsize=8)
                
                # Add value labels
                for i, v in enumerate(target_counts.values):
                    axes[idx, 0].text(i, v + max(target_counts.values)*0.02, str(v), 
                                     ha='center', va='bottom', fontsize=8)
            
            # Subplot 2: Missing values
            missing = df.isnull().sum()
            if missing.sum() > 0:
                missing = missing[missing > 0].sort_values(ascending=False)[:10]
                axes[idx, 1].barh(range(len(missing)), missing.values, color='coral', alpha=0.7)
                axes[idx, 1].set_yticks(range(len(missing)))
                axes[idx, 1].set_yticklabels(missing.index, fontsize=8)
                axes[idx, 1].set_title(f'{name}: Gi√° tr·ªã thi·∫øu', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('S·ªë l∆∞·ª£ng', fontsize=9)
            else:
                axes[idx, 1].text(0.5, 0.5, 'Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu', 
                                 ha='center', va='center', fontsize=10)
                axes[idx, 1].set_title(f'{name}: Gi√° tr·ªã thi·∫øu', fontsize=11, pad=10)
            axes[idx, 1].tick_params(labelsize=8)
            
            # Subplot 3: Feature types
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            categorical_cols = df.select_dtypes(include=['object']).columns
            
            type_counts = [len(numeric_cols), len(categorical_cols)]
            colors = ['lightgreen', 'lightcoral']
            axes[idx, 2].pie(type_counts, labels=['Numeric', 'Categorical'], 
                            autopct='%1.1f%%', colors=colors, textprops={'fontsize': 9})
            axes[idx, 2].set_title(f'{name}: Lo·∫°i Features', fontsize=11, pad=10)
        
        plt.tight_layout(pad=3.0)
        plt.subplots_adjust(top=0.96)
        plt.savefig('eda_analysis_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        print("\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì EDA: eda_analysis_all.png")
        plt.close()
    
    def _get_target_column(self, dataset_name, df):
        """X√°c ƒë·ªãnh c·ªôt target cho m·ªói dataset"""
        target_map = {
            'Wine': 'quality',
            'Diabetes': 'Outcome',
            'HeartDisease': 'num',
            'Adult': 'income',
            'Mushroom': 'class',
            'Sonar': 'Label',
            'CreditCard': 'Class'
        }
        return target_map.get(dataset_name)
    
    def preprocess_data(self):
        """
        B∆∞·ªõc 3: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi Pipeline (BEST PRACTICE)
        
        Quy tr√¨nh ƒê√öNG:
        1. Split train/test TR∆Ø·ªöC
        2. Fit preprocessing pipeline tr√™n train
        3. Transform c·∫£ train v√† test
        4. SMOTE/Undersample CH·ªà √°p d·ª•ng tr√™n train
        
        Tr√°nh DATA LEAKAGE!
        """
        print("\n" + "="*80)
        print("B∆Ø·ªöC 3: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (BEST PRACTICE - NO DATA LEAKAGE)")
        print("="*80)
        
        self.processed_datasets = {}
        self.pipelines = {}
        
        for name, dataset_info in self.datasets.items():
            print(f"\n{'='*60}")
            print(f"üîß X·ª≠ l√Ω {name} Dataset")
            print(f"{'='*60}")
            
            df = dataset_info['data'].copy()
            
            # B∆∞·ªõc 1: L·∫•y X, y TH√î (ch∆∞a preprocessing)
            if name == 'Wine':
                X, y = self._extract_wine(df)
            elif name == 'Diabetes':
                X, y = self._extract_diabetes(df)
            elif name == 'HeartDisease':
                X, y = self._extract_heartdisease(df)
            elif name == 'Adult':
                X, y = self._extract_adult(df)
            elif name == 'Mushroom':
                X, y = self._extract_mushroom(df)
            elif name == 'Sonar':
                X, y = self._extract_sonar(df)
            elif name == 'CreditCard':
                X, y = self._extract_creditcard(df)
            else:
                continue
            
            # B∆∞·ªõc 2: SPLIT TR∆Ø·ªöC KHI PREPROCESSING
            print(f"   üìä Original shape: {X.shape}")
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            print(f"   ‚úÇÔ∏è Split: Train={X_train.shape}, Test={X_test.shape}")
            
            # B∆∞·ªõc 3: BUILD PIPELINE cho t·ª´ng dataset
            pipeline = self._build_pipeline(name)
            self.pipelines[name] = pipeline
            
            # B∆∞·ªõc 4: FIT pipeline tr√™n TRAIN, transform c·∫£ train v√† test
            print(f"   üîß Fitting pipeline on TRAIN set...")
            X_train_transformed = pipeline.fit_transform(X_train, y_train)
            
            print(f"   üîÑ Transforming TEST set...")
            X_test_transformed = pipeline.transform(X_test)
            
            # B∆∞·ªõc 5: Apply SMOTE/Undersample CH·ªà tr√™n TRAIN (sau preprocessing)
            y_train_transformed = y_train
            
            if name == 'Diabetes':
                print(f"   ‚öñÔ∏è Applying SMOTE on TRAIN set...")
                smote = SMOTE(random_state=42)
                X_train_transformed, y_train_transformed = smote.fit_resample(X_train_transformed, y_train)
                print(f"      Before: {len(y_train)} samples ‚Üí After: {len(y_train_transformed)} samples")
            
            elif name == 'CreditCard':
                print(f"   ‚öñÔ∏è Applying Undersampling on TRAIN set...")
                rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
                X_train_transformed, y_train_transformed = rus.fit_resample(X_train_transformed, y_train)
                print(f"      Before: {len(y_train)} samples ‚Üí After: {len(y_train_transformed)} samples")
            
            # y_test KH√îNG bao gi·ªù resample!
            
            self.processed_datasets[name] = {
                'X_train': X_train_transformed,
                'X_test': X_test_transformed,
                'y_train': y_train_transformed,
                'y_test': y_test,
                'feature_count': X_train_transformed.shape[1]
            }
            
            print(f"   ‚úÖ Final - Train: {X_train_transformed.shape}, Test: {X_test_transformed.shape}")
    
    def _build_pipeline(self, dataset_name):
        """Build appropriate preprocessing pipeline for each dataset"""
        pipeline_map = {
            'Wine': self._build_pipeline_wine,
            'Diabetes': self._build_pipeline_diabetes,
            'HeartDisease': self._build_pipeline_heartdisease,
            'Adult': self._build_pipeline_adult,
            'Mushroom': self._build_pipeline_mushroom,
            'Sonar': self._build_pipeline_sonar,
            'CreditCard': self._build_pipeline_creditcard
        }
        
        if dataset_name in pipeline_map:
            return pipeline_map[dataset_name]()
        else:
            # Default pipeline
            return Pipeline([('scaler', StandardScaler())])
    
    def _extract_wine(self, df):
        """Extract raw X, y for Wine dataset (NO preprocessing yet)"""
        print("üç∑ Wine: Extracting features")
        y = (df['quality'] >= 6).astype(int)
        X = df.drop('quality', axis=1)
        
        # Feature Engineering (BEFORE split - domain knowledge)
        X['alcohol_sulphates'] = X['alcohol'] * X['sulphates']
        X['volatile_total_acidity'] = X['volatile acidity'] / (X['fixed acidity'] + 0.001)
        
        return X.values, y.values
    
    def _build_pipeline_wine(self):
        """Build preprocessing pipeline for Wine dataset"""
        return Pipeline([
            ('scaler', RobustScaler())
        ])
    
    def _extract_diabetes(self, df):
        """Extract raw X, y for Diabetes dataset"""
        print("üíâ Diabetes: Extracting features")
        y = df['Outcome'].values
        X = df.drop('Outcome', axis=1).copy()
        
        # Replace medical impossibilities (0 values) with NaN
        zero_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
        for col in zero_cols:
            if col in X.columns:
                X[col] = X[col].replace(0, np.nan)
        
        return X.values, y
    
    def _build_pipeline_diabetes(self):
        """Build preprocessing pipeline for Diabetes dataset"""
        # SMOTE s·∫Ω ƒë∆∞·ª£c apply ri√™ng sau khi transform
        return Pipeline([
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ])
    
    def _extract_heartdisease(self, df):
        """Extract raw X, y for Heart Disease dataset"""
        print("‚ù§Ô∏è HeartDisease: Extracting features")
        
        # Binary classification: num > 0 = heart disease (1), num = 0 = no disease (0)
        y = (df['num'] > 0).astype(int).values
        X = df.drop(['num', 'id'], axis=1, errors='ignore').copy()
        
        # Handle categorical columns
        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
        for col in categorical_cols:
            X[col] = X[col].fillna(X[col].mode()[0] if not X[col].mode().empty else 'missing')
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        # Handle numeric columns
        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) > 0:
            imputer = SimpleImputer(strategy='median')
            X[numeric_cols] = imputer.fit_transform(X[numeric_cols])
        
        return X.values, y
    
    def _build_pipeline_heartdisease(self):
        """Build preprocessing pipeline for Heart Disease dataset"""
        return Pipeline([
            ('scaler', StandardScaler())
        ])
    
    def _extract_adult(self, df):
        """Extract raw X, y for Adult dataset"""
        print("üë§ Adult: Extracting features")
        df.columns = df.columns.str.strip()
        
        y = LabelEncoder().fit_transform(df['income'])
        X = df.drop(['income'], axis=1).copy()
        
        # Handle missing values
        X = X.replace('?', np.nan)
        
        # Separate numeric and categorical
        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
        
        # Impute and encode categorical BEFORE split (necessary for proper encoding)
        for col in categorical_cols:
            X[col] = X[col].fillna(X[col].mode()[0] if not X[col].mode().empty else 'missing')
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        # Impute numeric
        if len(numeric_cols) > 0:
            imputer = SimpleImputer(strategy='median')
            X[numeric_cols] = imputer.fit_transform(X[numeric_cols])
        
        return X.values, y
    
    def _build_pipeline_adult(self):
        """Build preprocessing pipeline for Adult dataset"""
        return Pipeline([
            ('scaler', StandardScaler())
        ])
    
    def _extract_mushroom(self, df):
        """Extract raw X, y for Mushroom dataset"""
        print("üçÑ Mushroom: Extracting features")
        y = LabelEncoder().fit_transform(df['class'])
        X = df.drop('class', axis=1).copy()
        
        # Label encode all categorical features
        for col in X.columns:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        return X.values, y
    
    def _build_pipeline_mushroom(self):
        """Build preprocessing pipeline for Mushroom dataset"""
        return Pipeline([
            ('feature_selection', SelectKBest(mutual_info_classif, k=15))
        ])
    
    def _extract_sonar(self, df):
        """Extract raw X, y for Sonar dataset"""
        print("üì° Sonar: Extracting features")
        y = LabelEncoder().fit_transform(df.iloc[:, -1])
        X = df.iloc[:, :-1].values
        return X, y
    
    def _build_pipeline_sonar(self):
        """Build preprocessing pipeline for Sonar dataset"""
        return Pipeline([
            ('scaler', StandardScaler()),
            ('pca', PCA(n_components=30, random_state=42))
        ])
    
    def _extract_creditcard(self, df):
        """Extract raw X, y for Credit Card dataset"""
        print("üí≥ Credit Card: Extracting features")
        y = df['Class'].values
        X = df.drop('Class', axis=1).copy()
        
        # Scale Time and Amount (V1-V28 already scaled)
        scaler = StandardScaler()
        X[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])
        
        return X.values, y
    
    def _build_pipeline_creditcard(self):
        """Build preprocessing pipeline for Credit Card dataset"""
        return Pipeline([
            ('passthrough', FunctionTransformer())  # Identity transform
        ])
    
    def apply_dimensionality_reduction(self):
        """B∆∞·ªõc 3.5: √Åp d·ª•ng gi·∫£m chi·ªÅu cho c√°c datasets ph√π h·ª£p"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 3.5: GI·∫¢M CHI·ªÄU D·ªÆ LI·ªÜU")
        print("="*80)
        
        for name in ['Wine', 'Adult', 'CreditCard']:
            if name in self.processed_datasets:
                print(f"\nüî¨ √Åp d·ª•ng PCA cho {name}")
                
                X_train = self.processed_datasets[name]['X_train']
                X_test = self.processed_datasets[name]['X_test']
                
                # Determine optimal components
                n_components = min(10, X_train.shape[1] // 2)
                
                pca = PCA(n_components=n_components, random_state=42)
                X_train_pca = pca.fit_transform(X_train)
                X_test_pca = pca.transform(X_test)
                
                print(f"   Original features: {X_train.shape[1]}")
                print(f"   Reduced to: {n_components}")
                print(f"   Variance explained: {pca.explained_variance_ratio_.sum():.2%}")
                
                # Store both versions
                self.processed_datasets[f"{name}_PCA"] = {
                    'X_train': X_train_pca,
                    'X_test': X_test_pca,
                    'y_train': self.processed_datasets[name]['y_train'],
                    'y_test': self.processed_datasets[name]['y_test'],
                    'feature_count': n_components
                }
    
    def train_models(self):
        """
        B∆∞·ªõc 4: X√¢y d·ª±ng m√¥ h√¨nh v·ªõi hyperparameter tuning
        
        Train 2 models:
        1. Random Forest: Ensemble of decision trees
        2. Naive Bayes: Probabilistic classifier (GaussianNB)
        """
        print("\n" + "="*80)
        print("B∆Ø·ªöC 4: X√ÇY D·ª∞NG M√î H√åNH (V·ªöI TUNING)")
        print("="*80)
        
        self.models = {}
        
        for name, data in self.processed_datasets.items():
            print(f"\n{'='*60}")
            print(f"üî® Training tr√™n {name}")
            print(f"{'='*60}")
            
            X_train, y_train = data['X_train'], data['y_train']
            
            # ============================================================
            # RANDOM FOREST CLASSIFIER
            # ============================================================
            print("üå≤ Random Forest...")
            rf = RandomForestClassifier(
                n_estimators=100,        # S·ªë l∆∞·ª£ng trees trong forest
                max_depth=15,            # ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa m·ªói tree (tr√°nh overfitting)
                min_samples_split=5,     # Min s·ªë samples ƒë·ªÉ split node
                min_samples_leaf=2,      # Min s·ªë samples ·ªü leaf node
                random_state=42,         # Random seed ƒë·ªÉ reproducible
                n_jobs=-1                # D√πng t·∫•t c·∫£ CPU cores (parallel)
            )
            # C√°ch ho·∫°t ƒë·ªông:
            # 1. T·∫°o 100 decision trees
            # 2. M·ªói tree train tr√™n random subset c·ªßa data (bagging)
            # 3. M·ªói split ch·ªçn random subset c·ªßa features
            # 4. Prediction: Vote t·ª´ 100 trees (majority voting)
            rf.fit(X_train, y_train)
            
            # ============================================================
            # NAIVE BAYES CLASSIFIER
            # ============================================================
            print("üéØ Naive Bayes...")
            # D√πng GaussianNB v√¨ t·∫•t c·∫£ features ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang numeric
            # GaussianNB gi·∫£ ƒë·ªãnh features follow Gaussian distribution
            nb = GaussianNB()
            
            # C√°ch ho·∫°t ƒë·ªông:
            # 1. T√≠nh P(y) - Prior probability c·ªßa m·ªói class
            # 2. T√≠nh P(xi|y) - Likelihood c·ªßa feature xi given class y
            # 3. Prediction: P(y|X) = P(y) * ‚àèP(xi|y) / P(X) (Bayes' theorem)
            # 4. Gi·∫£ ƒë·ªãnh: Features ƒë·ªôc l·∫≠p (naive assumption)
            nb.fit(X_train, y_train)
            
            self.models[name] = {
                'rf': rf,
                'nb': nb
            }
            
            print(f"‚úÖ {name} ho√†n th√†nh")
    
    def evaluate_models(self):
        """
        B∆∞·ªõc 5: ƒê√°nh gi√° m√¥ h√¨nh v·ªõi nhi·ªÅu metrics
        
        Metrics ƒë∆∞·ª£c d√πng:
        1. Accuracy: T·ªïng th·ªÉ ƒë√∫ng bao nhi√™u %
        2. Precision: Trong d·ª± ƒëo√°n positive, ƒë√∫ng bao nhi√™u %
        3. Recall: Trong positive th·∫≠t, catch ƒë∆∞·ª£c bao nhi√™u %
        4. F1-Score: Harmonic mean c·ªßa Precision v√† Recall
        5. AUC-ROC: Kh·∫£ nƒÉng ph√¢n bi·ªát classes
        """
        print("\n" + "="*80)
        print("B∆Ø·ªöC 5: ƒê√ÅNH GI√Å M√î H√åNH")
        print("="*80)
        
        self.results = {}
        
        for name, models in self.models.items():
            print(f"\n{'='*60}")
            print(f"üìä ƒê√°nh gi√° {name}")
            print(f"{'='*60}")
            
            data = self.processed_datasets[name]
            X_test, y_test = data['X_test'], data['y_test']
            
            for model_name, model in models.items():
                model_key = f"{model_name.upper()}_{name}"
                
                # Predictions
                y_pred = model.predict(X_test)              # Class predictions (0 ho·∫∑c 1)
                y_proba = model.predict_proba(X_test)[:, 1]  # Probability c·ªßa class 1
                
                # ============================================================
                # T√çNH C√ÅC METRICS
                # ============================================================
                
                # 1. ACCURACY = (TP + TN) / Total
                #    √ù nghƒ©a: T·ªïng th·ªÉ ƒë√∫ng bao nhi√™u %
                accuracy = accuracy_score(y_test, y_pred)
                
                # 2. PRECISION = TP / (TP + FP)
                #    √ù nghƒ©a: Trong nh·ªØng c√°i d·ª± ƒëo√°n l√† positive, bao nhi√™u % ƒë√∫ng?
                #    Quan tr·ªçng khi: False Positive t·ªën k√©m
                precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 3. RECALL (Sensitivity) = TP / (TP + FN)
                #    √ù nghƒ©a: Trong t·∫•t c·∫£ positive th·∫≠t, model catch ƒë∆∞·ª£c bao nhi√™u %?
                #    Quan tr·ªçng khi: False Negative nguy hi·ªÉm (VD: ung th∆∞)
                recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 4. F1-SCORE = 2 * (Precision * Recall) / (Precision + Recall)
                #    √ù nghƒ©a: Harmonic mean, c√¢n b·∫±ng gi·ªØa Precision v√† Recall
                #    D√πng khi: Imbalanced data ho·∫∑c c·∫ßn c√¢n b·∫±ng c·∫£ 2
                f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 5. AUC-ROC (Area Under ROC Curve)
                #    √ù nghƒ©a: Kh·∫£ nƒÉng model ph√¢n bi·ªát 2 classes
                #    AUC = 1.0: Perfect, AUC = 0.5: Random guessing
                auc = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) == 2 else 0
                
                self.results[model_key] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'auc': auc,
                    'predictions': (y_pred, y_proba),
                    'y_test': y_test
                }
                
                print(f"{model_name.upper()}: Accuracy={accuracy:.4f}, "
                      f"F1={f1:.4f}, AUC={auc:.4f}")
    
    def visualize_results(self):
        """B∆∞·ªõc 6: Tr·ª±c quan h√≥a k·∫øt qu·∫£ to√†n di·ªán"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 6: TR·ª∞C QUAN H√ìA K·∫æT QU·∫¢")
        print("="*80)
        
        # Create comprehensive comparison
        self._plot_overall_comparison()
        self._plot_dataset_comparisons()
        print("‚úÖ ƒê√£ l∆∞u c√°c bi·ªÉu ƒë·ªì k·∫øt qu·∫£")
    
    def _plot_overall_comparison(self):
        """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh t·ªïng th·ªÉ"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 14))
        fig.suptitle('SO S√ÅNH T·ªîNG TH·ªÇ: RANDOM FOREST vs NAIVE BAYES', 
                    fontsize=16, fontweight='bold')
        
        # 1. Accuracy comparison
        ax1 = axes[0, 0]
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        rf_acc = [self.results.get(f"RF_{d}", {}).get('accuracy', 0) for d in datasets]
        nb_acc = [self.results.get(f"NB_{d}", {}).get('accuracy', 0) for d in datasets]
        
        x = np.arange(len(datasets))
        width = 0.35
        ax1.bar(x - width/2, rf_acc, width, label='Random Forest', color='darkgreen', alpha=0.8)
        ax1.bar(x + width/2, nb_acc, width, label='Naive Bayes', color='orange', alpha=0.8)
        ax1.set_xlabel('Dataset', fontsize=10)
        ax1.set_ylabel('Accuracy', fontsize=10)
        ax1.set_title('Accuracy Comparison', fontsize=12, pad=15)
        ax1.set_xticks(x)
        ax1.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax1.legend(fontsize=9)
        ax1.grid(True, alpha=0.3)
        
        # 2. F1-Score comparison
        ax2 = axes[0, 1]
        rf_f1 = [self.results.get(f"RF_{d}", {}).get('f1', 0) for d in datasets]
        nb_f1 = [self.results.get(f"NB_{d}", {}).get('f1', 0) for d in datasets]
        
        ax2.bar(x - width/2, rf_f1, width, label='Random Forest', color='darkblue', alpha=0.8)
        ax2.bar(x + width/2, nb_f1, width, label='Naive Bayes', color='red', alpha=0.8)
        ax2.set_xlabel('Dataset', fontsize=10)
        ax2.set_ylabel('F1-Score', fontsize=10)
        ax2.set_title('F1-Score Comparison', fontsize=12, pad=15)
        ax2.set_xticks(x)
        ax2.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax2.legend(fontsize=9)
        ax2.grid(True, alpha=0.3)
        
        # 3. Average metrics
        ax3 = axes[1, 0]
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        rf_avg = [np.mean([self.results.get(f"RF_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        nb_avg = [np.mean([self.results.get(f"NB_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        
        x_m = np.arange(len(metrics))
        ax3.bar(x_m - width/2, rf_avg, width, label='Random Forest', color='purple', alpha=0.8)
        ax3.bar(x_m + width/2, nb_avg, width, label='Naive Bayes', color='pink', alpha=0.8)
        ax3.set_xlabel('Metrics', fontsize=10)
        ax3.set_ylabel('Average Score', fontsize=10)
        ax3.set_title('Average Performance Across All Datasets', fontsize=12, pad=15)
        ax3.set_xticks(x_m)
        ax3.set_xticklabels(metrics, fontsize=9)
        ax3.legend(fontsize=9)
        ax3.grid(True, alpha=0.3)
        
        # 4. Win/Loss count
        ax4 = axes[1, 1]
        rf_wins = sum(1 for d in datasets if self.results.get(f"RF_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"NB_{d}", {}).get('accuracy', 0))
        nb_wins = sum(1 for d in datasets if self.results.get(f"NB_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"RF_{d}", {}).get('accuracy', 0))
        
        ax4.pie([rf_wins, nb_wins], labels=['RF Wins', 'NB Wins'], 
               autopct='%1.0f%%', colors=['darkgreen', 'orange'], 
               textprops={'fontsize': 11})
        ax4.set_title('Win Rate (by Accuracy)', fontsize=12, pad=15)
        
        plt.tight_layout()
        plt.savefig('overall_comparison.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def _plot_dataset_comparisons(self):
        """V·∫Ω confusion matrices cho c√°c datasets"""
        num_datasets = len(self.models)
        fig, axes = plt.subplots(num_datasets, 2, figsize=(12, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('CONFUSION MATRICES - T·∫§T C·∫¢ DATASETS', 
                    fontsize=16, fontweight='bold', y=0.995)
        
        for idx, name in enumerate(self.models.keys()):
            # RF Confusion Matrix
            rf_key = f"RF_{name}"
            if rf_key in self.results:
                y_pred, _ = self.results[rf_key]['predictions']
                y_test = self.results[rf_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[idx, 0],
                           annot_kws={'size': 10})
                axes[idx, 0].set_title(f'Random Forest - {name}', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Predicted', fontsize=9)
                axes[idx, 0].set_ylabel('Actual', fontsize=9)
            
            # NB Confusion Matrix
            nb_key = f"NB_{name}"
            if nb_key in self.results:
                y_pred, _ = self.results[nb_key]['predictions']
                y_test = self.results[nb_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=axes[idx, 1],
                           annot_kws={'size': 10})
                axes[idx, 1].set_title(f'Naive Bayes - {name}', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('Predicted', fontsize=9)
                axes[idx, 1].set_ylabel('Actual', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.96)
        plt.savefig('confusion_matrices_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def generate_report(self):
        """B∆∞·ªõc 7: T·∫°o b√°o c√°o k·∫øt qu·∫£ chi ti·∫øt"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 7: B√ÅO C√ÅO K·∫æT QU·∫¢ CHI TI·∫æT")
        print("="*80)
        
        # Overall summary
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        
        print(f"\nüìä T·ªîNG QUAN:")
        print("="*60)
        print(f"T·ªïng s·ªë datasets: {len(datasets)}")
        print(f"T·ªïng s·ªë m√¥ h√¨nh: {len(self.results)}")
        
        # Best performers
        print(f"\nüèÜ HI·ªÜU SU·∫§T THEO DATASET:")
        print("="*60)
        
        for dataset in datasets:
            rf_acc = self.results.get(f"RF_{dataset}", {}).get('accuracy', 0)
            nb_acc = self.results.get(f"NB_{dataset}", {}).get('accuracy', 0)
            
            winner = "Random Forest" if rf_acc > nb_acc else "Naive Bayes"
            print(f"\n{dataset}:")
            print(f"  RF: Acc={rf_acc:.4f}")
            print(f"  NB: Acc={nb_acc:.4f}")
            print(f"  ‚ú® Winner: {winner}")
        
        # Average performance
        print(f"\nüìà HI·ªÜU SU·∫§T TRUNG B√åNH:")
        print("="*60)
        
        rf_avg_acc = np.mean([self.results.get(f"RF_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        nb_avg_acc = np.mean([self.results.get(f"NB_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        
        print(f"Random Forest: {rf_avg_acc:.4f}")
        print(f"Naive Bayes: {nb_avg_acc:.4f}")
        
        # Conclusions
        print(f"\nüí° K·∫æT LU·∫¨N:")
        print("="*60)
        print("‚úÖ Random Forest:")
        print("   - T·ªët h∆°n tr√™n d·ªØ li·ªáu numeric ph·ª©c t·∫°p")
        print("   - X·ª≠ l√Ω t·ªët outliers v√† missing values")
        print("   - Hi·ªáu su·∫•t cao v·ªõi feature engineering")
        
        print("\n‚úÖ Naive Bayes:")
        print("   - Hi·ªáu qu·∫£ v·ªõi text classification")
        print("   - Nhanh v√† ƒë∆°n gi·∫£n")
        print("   - T·ªët v·ªõi categorical data")
        
        print(f"\nüîß K·ª∏ THU·∫¨T ƒê√É √ÅP D·ª§NG:")
        print("="*60)
        print("‚úì Imputation (median/mode)")
        print("‚úì Scaling (Standard/Robust/MinMax)")
        print("‚úì Feature Engineering")
        print("‚úì Feature Selection (Chi2, Mutual Info)")
        print("‚úì Dimensionality Reduction (PCA)")
        print("‚úì Imbalanced Data Handling (SMOTE, Undersampling)")
        print("‚úì Cross-validation")
    
    def run_experiment(self):
        """Ch·∫°y to√†n b·ªô th√≠ nghi·ªám"""
        print("üöÄ B·∫ÆT ƒê·∫¶U TH·ª∞C NGHI·ªÜM N√ÇNG CAO")
        print("üìã Random Forest vs Naive Bayes tr√™n Multiple Datasets")
        print("üî¨ V·ªõi c√°c k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω v√† khai th√°c d·ªØ li·ªáu n√¢ng cao")
        
        if not self.load_datasets():
            print("‚ùå Kh√¥ng th·ªÉ t·∫£i datasets!")
            return
        
        self.explore_data()
        self.preprocess_data()
        # Skip apply_dimensionality_reduction() - PCA ƒë√£ c√≥ trong pipeline c·ªßa Sonar
        # self.apply_dimensionality_reduction()
        self.train_models()
        self.evaluate_models()
        self.visualize_results()
        self.generate_report()
        
        print("\n" + "="*80)
        print("üéâ TH·ª∞C NGHI·ªÜM HO√ÄN TH√ÄNH!")
        print("="*80)
        print("üìÅ C√°c file ƒë√£ ƒë∆∞·ª£c t·∫°o:")
        print("   üìä eda_analysis_all.png - Kh√°m ph√° d·ªØ li·ªáu")
        print("   üìà overall_comparison.png - So s√°nh t·ªïng th·ªÉ")
        print("   üéØ confusion_matrices_all.png - Confusion matrices")

if __name__ == "__main__":
    experiment = AdvancedDataMiningExperiment()
    experiment.run_experiment()
