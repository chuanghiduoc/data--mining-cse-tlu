#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TH·ª∞C NGHI·ªÜM SO S√ÅNH RANDOM FOREST V√Ä NAIVE BAYES
V·ªõi nhi·ªÅu datasets v√† k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω n√¢ng cao

Author: Student
Date: 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (classification_report, confusion_matrix, 
                           accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve)
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, RFE
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
import warnings
warnings.filterwarnings('ignore')

# Thi·∫øt l·∫≠p font cho ti·∫øng Vi·ªát
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.style.use('seaborn-v0_8')

class AdvancedDataMiningExperiment:
    """
    Class th·ª±c hi·ªán th√≠ nghi·ªám khai ph√° d·ªØ li·ªáu n√¢ng cao v·ªõi nhi·ªÅu datasets
    
    M·ª•c ƒë√≠ch: So s√°nh Random Forest v√† Naive Bayes tr√™n nhi·ªÅu lo·∫°i d·ªØ li·ªáu kh√°c nhau
    v·ªõi c√°c k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω n√¢ng cao
    """
    
    def __init__(self):
        """
        Kh·ªüi t·∫°o experiment
        - results: L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh (accuracy, precision, recall, f1, auc)
        - datasets: L∆∞u d·ªØ li·ªáu th√¥ ƒë√£ load
        - feature_importance: L∆∞u ƒë·ªô quan tr·ªçng c·ªßa features (t·ª´ Random Forest)
        """
        self.results = {}
        self.datasets = {}
        self.feature_importance = {}
        
    def load_datasets(self):
        """B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu - T·∫£i t·∫•t c·∫£ datasets"""
        print("="*80)
        print("B∆Ø·ªöC 1: THU TH·∫¨P D·ªÆ LI·ªÜU")
        print("="*80)
        
        datasets_config = {
            'Wine': {
                'path': 'datasets/winequality-red.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'Diabetes': {
                'path': 'datasets/diabetes.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'Adult': {
                'path': 'datasets/adult.csv',
                'encoding': 'utf-8',
                'type': 'mixed'
            },
            'Mushroom': {
                'path': 'datasets/mushrooms.csv',
                'encoding': 'utf-8',
                'type': 'categorical'
            },
            'Sonar': {
                'path': 'datasets/sonar-all-data.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'CreditCard': {
                'path': 'datasets/creditcard.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            }
        }
        
        successful_loads = 0
        
        for name, config in datasets_config.items():
            try:
                print(f"\nüìä ƒêang t·∫£i {name} Dataset...")
                df = pd.read_csv(config['path'], encoding=config['encoding'])
                
                self.datasets[name] = {
                    'data': df,
                    'type': config['type'],
                    'shape': df.shape
                }
                
                print(f"   ‚úÖ {name}: {df.shape[0]} m·∫´u, {df.shape[1]} c·ªôt")
                successful_loads += 1
                
            except Exception as e:
                print(f"   ‚ùå L·ªói t·∫£i {name}: {e}")
            
        print(f"\n‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {successful_loads}/{len(datasets_config)} datasets")
        return successful_loads > 0
    
    def explore_data(self):
        """B∆∞·ªõc 2: Kh√°m ph√° d·ªØ li·ªáu (EDA) v·ªõi ph√¢n t√≠ch chi ti·∫øt"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 2: KH√ÅM PH√Å D·ªÆ LI·ªÜU (EDA)")
        print("="*80)
        
        for name, dataset_info in self.datasets.items():
            df = dataset_info['data']
            print(f"\n{'='*60}")
            print(f"üìä {name.upper()} DATASET")
            print(f"{'='*60}")
            print(f"K√≠ch th∆∞·ªõc: {df.shape}")
            print(f"Lo·∫°i d·ªØ li·ªáu: {dataset_info['type']}")
            print(f"\nTh√¥ng tin c·ªôt:")
            print(df.dtypes)
            print(f"\nGi√° tr·ªã null:")
            print(df.isnull().sum())
            print(f"\nTh·ªëng k√™ m√¥ t·∫£:")
            print(df.describe())
        
        # Visualization
        self.visualize_eda()
    
    def visualize_eda(self):
        """V·∫Ω bi·ªÉu ƒë·ªì kh√°m ph√° d·ªØ li·ªáu cho t·∫•t c·∫£ datasets"""
        num_datasets = len(self.datasets)
        fig, axes = plt.subplots(num_datasets, 3, figsize=(20, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('KH√ÅM PH√Å D·ªÆ LI·ªÜU - T·∫§T C·∫¢ DATASETS', fontsize=18, fontweight='bold', y=0.995)
        
        for idx, (name, dataset_info) in enumerate(self.datasets.items()):
            df = dataset_info['data']
            
            # Subplot 1: Distribution of target
            target_col = self._get_target_column(name, df)
            if target_col:
                target_counts = df[target_col].value_counts()
                axes[idx, 0].bar(range(len(target_counts)), target_counts.values, color='steelblue', alpha=0.7)
                axes[idx, 0].set_title(f'{name}: Ph√¢n b·ªë Target', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Class', fontsize=9)
                axes[idx, 0].set_ylabel('S·ªë l∆∞·ª£ng', fontsize=9)
                axes[idx, 0].tick_params(labelsize=8)
                
                # Add value labels
                for i, v in enumerate(target_counts.values):
                    axes[idx, 0].text(i, v + max(target_counts.values)*0.02, str(v), 
                                     ha='center', va='bottom', fontsize=8)
            
            # Subplot 2: Missing values
            missing = df.isnull().sum()
            if missing.sum() > 0:
                missing = missing[missing > 0].sort_values(ascending=False)[:10]
                axes[idx, 1].barh(range(len(missing)), missing.values, color='coral', alpha=0.7)
                axes[idx, 1].set_yticks(range(len(missing)))
                axes[idx, 1].set_yticklabels(missing.index, fontsize=8)
                axes[idx, 1].set_title(f'{name}: Gi√° tr·ªã thi·∫øu', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('S·ªë l∆∞·ª£ng', fontsize=9)
            else:
                axes[idx, 1].text(0.5, 0.5, 'Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu', 
                                 ha='center', va='center', fontsize=10)
                axes[idx, 1].set_title(f'{name}: Gi√° tr·ªã thi·∫øu', fontsize=11, pad=10)
            axes[idx, 1].tick_params(labelsize=8)
            
            # Subplot 3: Feature types
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            categorical_cols = df.select_dtypes(include=['object']).columns
            
            type_counts = [len(numeric_cols), len(categorical_cols)]
            colors = ['lightgreen', 'lightcoral']
            axes[idx, 2].pie(type_counts, labels=['Numeric', 'Categorical'], 
                            autopct='%1.1f%%', colors=colors, textprops={'fontsize': 9})
            axes[idx, 2].set_title(f'{name}: Lo·∫°i Features', fontsize=11, pad=10)
        
        plt.tight_layout(pad=3.0)
        plt.subplots_adjust(top=0.96)
        plt.savefig('eda_analysis_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        print("\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì EDA: eda_analysis_all.png")
        plt.close()
    
    def _get_target_column(self, dataset_name, df):
        """X√°c ƒë·ªãnh c·ªôt target cho m·ªói dataset"""
        target_map = {
            'Wine': 'quality',
            'Diabetes': 'Outcome',
            'Adult': 'income',
            'Mushroom': 'class',
            'Sonar': 'Label',
            'CreditCard': 'Class'
        }
        return target_map.get(dataset_name)
    
    def preprocess_data(self):
        """B∆∞·ªõc 3: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi nhi·ªÅu k·ªπ thu·∫≠t n√¢ng cao"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 3: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (N√ÇNG CAO)")
        print("="*80)
        
        self.processed_datasets = {}
        
        for name, dataset_info in self.datasets.items():
            print(f"\n{'='*60}")
            print(f"üîß X·ª≠ l√Ω {name} Dataset")
            print(f"{'='*60}")
            
            df = dataset_info['data'].copy()
            
            if name == 'Wine':
                X, y = self._preprocess_wine(df)
            elif name == 'Diabetes':
                X, y = self._preprocess_diabetes(df)
            elif name == 'Adult':
                X, y = self._preprocess_adult(df)
            elif name == 'Mushroom':
                X, y = self._preprocess_mushroom(df)
            elif name == 'Sonar':
                X, y = self._preprocess_sonar(df)
            elif name == 'CreditCard':
                X, y = self._preprocess_creditcard(df)
            else:
                continue
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            self.processed_datasets[name] = {
                'X_train': X_train,
                'X_test': X_test,
                'y_train': y_train,
                'y_test': y_test,
                'feature_count': X.shape[1]
            }
            
            print(f"‚úÖ Train: {X_train.shape}, Test: {X_test.shape}")
    
    def _preprocess_wine(self, df):
        """
        Ti·ªÅn x·ª≠ l√Ω Wine dataset
        
        K·ªπ thu·∫≠t √°p d·ª•ng:
        1. Binary classification: Chuy·ªÉn quality th√†nh 2 l·ªõp (good/bad)
        2. Feature Engineering: T·∫°o features t∆∞∆°ng t√°c
        3. RobustScaler: Scaling ch·ªëng outliers
        """
        print("üç∑ Wine: Scaling + Feature Engineering")
        
        # B∆∞·ªõc 1: Chuy·ªÉn sang binary classification
        # quality >= 6: good wine (1), quality < 6: bad wine (0)
        y = (df['quality'] >= 6).astype(int)
        X = df.drop('quality', axis=1)
        
        # B∆∞·ªõc 2: Feature Engineering - T·∫°o features m·ªõi t·ª´ s·ª± t∆∞∆°ng t√°c
        # alcohol * sulphates: T∆∞∆°ng t√°c gi·ªØa ƒë·ªô c·ªìn v√† sulphates
        X['alcohol_sulphates'] = X['alcohol'] * X['sulphates']
        
        # volatile acidity / fixed acidity: T·ª∑ l·ªá acid d·ªÖ bay h∆°i
        # +0.001 ƒë·ªÉ tr√°nh chia cho 0
        X['volatile_total_acidity'] = X['volatile acidity'] / (X['fixed acidity'] + 0.001)
        
        # B∆∞·ªõc 3: RobustScaler - Scaling d·ª±a tr√™n median v√† IQR
        # ∆Øu ƒëi·ªÉm: √çt b·ªã ·∫£nh h∆∞·ªüng b·ªüi outliers h∆°n StandardScaler
        # C√¥ng th·ª©c: X_scaled = (X - median) / IQR
        scaler = RobustScaler()
        X = scaler.fit_transform(X)
        
        print(f"   Features: {X.shape[1]}")
        return X, y
    
    def _preprocess_diabetes(self, df):
        """
        Ti·ªÅn x·ª≠ l√Ω Diabetes dataset
        
        K·ªπ thu·∫≠t √°p d·ª•ng:
        1. Smart Imputation: X·ª≠ l√Ω gi√° tr·ªã 0 kh√¥ng h·ª£p l√Ω (medical impossibility)
        2. StandardScaler: Chu·∫©n h√≥a d·ªØ li·ªáu
        3. SMOTE: X·ª≠ l√Ω imbalanced data (tƒÉng minority class)
        """
        print("üíâ Diabetes: Imputation + Scaling + SMOTE")
        
        y = df['Outcome']  # Target: 1=c√≥ ti·ªÉu ƒë∆∞·ªùng, 0=kh√¥ng
        X = df.drop('Outcome', axis=1)
        
        # B∆∞·ªõc 1: X·ª≠ l√Ω gi√° tr·ªã 0 kh√¥ng h·ª£p l√Ω v·ªÅ m·∫∑t y h·ªçc
        # VD: Glucose=0, BloodPressure=0, BMI=0 l√† kh√¥ng th·ªÉ
        # ‚Üí Thay b·∫±ng NaN ƒë·ªÉ impute sau
        zero_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
        for col in zero_cols:
            if col in X.columns:
                X[col] = X[col].replace(0, np.nan)  # 0 ‚Üí NaN
        
        # B∆∞·ªõc 2: Imputation - ƒêi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng median
        # D√πng median thay v√¨ mean v√¨ √≠t b·ªã ·∫£nh h∆∞·ªüng b·ªüi outliers
        imputer = SimpleImputer(strategy='median')
        X = imputer.fit_transform(X)
        
        # B∆∞·ªõc 3: StandardScaler - Chu·∫©n h√≥a v·ªÅ mean=0, std=1
        # C√¥ng th·ª©c: X_scaled = (X - mean) / std
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        # B∆∞·ªõc 4: SMOTE (Synthetic Minority Over-sampling Technique)
        # X·ª≠ l√Ω imbalanced data b·∫±ng c√°ch t·∫°o synthetic samples cho minority class
        # C√°ch ho·∫°t ƒë·ªông:
        # 1. Ch·ªçn 1 sample t·ª´ minority class
        # 2. T√¨m k-nearest neighbors
        # 3. T·∫°o sample m·ªõi gi·ªØa sample g·ªëc v√† neighbor
        smote = SMOTE(random_state=42)
        X, y = smote.fit_resample(X, y)
        
        print(f"   Features: {X.shape[1]}, Samples sau SMOTE: {X.shape[0]}")
        return X, y
    
    def _preprocess_adult(self, df):
        """Ti·ªÅn x·ª≠ l√Ω Adult dataset"""
        print("üë§ Adult: Mixed data handling + Encoding")
        
        # Clean column names
        df.columns = df.columns.str.strip()
        
        # Target
        y = LabelEncoder().fit_transform(df['income'])
        
        # Drop target and unnecessary columns
        X = df.drop(['income'], axis=1)
        
        # Handle missing values (marked as '?')
        X = X.replace('?', np.nan)
        
        # Separate numeric and categorical
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        categorical_cols = X.select_dtypes(include=['object']).columns
        
        # Impute numeric
        if len(numeric_cols) > 0:
            X[numeric_cols] = SimpleImputer(strategy='median').fit_transform(X[numeric_cols])
        
        # Impute and encode categorical
        for col in categorical_cols:
            X[col] = X[col].fillna(X[col].mode()[0])
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        # Scale
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        print(f"   Features: {X.shape[1]}")
        return X, y
    
    def _preprocess_mushroom(self, df):
        """
        Ti·ªÅn x·ª≠ l√Ω Mushroom dataset
        
        K·ªπ thu·∫≠t √°p d·ª•ng:
        1. Label Encoding: Chuy·ªÉn categorical ‚Üí numeric
        2. Feature Selection: Ch·ªçn features quan tr·ªçng b·∫±ng Mutual Information
        
        L√Ω do: Mushroom dataset c√≥ 23 categorical features
        ‚Üí C·∫ßn encode sang numeric ƒë·ªÉ Random Forest v√† Naive Bayes x·ª≠ l√Ω ƒë∆∞·ª£c
        """
        print("üçÑ Mushroom: Categorical encoding + Feature selection")
        
        # Target: 'e'=edible (ƒÉn ƒë∆∞·ª£c), 'p'=poisonous (ƒë·ªôc)
        # LabelEncoder chuy·ªÉn 'e'‚Üí0, 'p'‚Üí1
        y = LabelEncoder().fit_transform(df['class'])
        X = df.drop('class', axis=1)
        
        # Label Encoding cho t·∫•t c·∫£ categorical features
        # VD: cap-shape: 'b'‚Üí0, 'c'‚Üí1, 'x'‚Üí2, 'f'‚Üí3, 'k'‚Üí4, 's'‚Üí5
        for col in X.columns:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        X = X.values  # Chuy·ªÉn DataFrame ‚Üí numpy array
        
        # Feature Selection b·∫±ng Mutual Information
        # Mutual Information ƒëo "th√¥ng tin chung" gi·ªØa feature v√† target
        # Ch·ªçn top 15 features c√≥ MI cao nh·∫•t (quan tr·ªçng nh·∫•t)
        # ∆Øu ƒëi·ªÉm: Kh√¥ng gi·∫£ ƒë·ªãnh linear relationship nh∆∞ correlation
        selector = SelectKBest(mutual_info_classif, k=min(15, X.shape[1]))
        X = selector.fit_transform(X, y)
        
        print(f"   Features sau selection: {X.shape[1]}")
        return X, y
    
    def _preprocess_sonar(self, df):
        """
        Ti·ªÅn x·ª≠ l√Ω Sonar dataset
        
        K·ªπ thu·∫≠t √°p d·ª•ng:
        1. StandardScaler: Chu·∫©n h√≥a d·ªØ li·ªáu
        2. PCA: Gi·∫£m chi·ªÅu t·ª´ 60‚Üí30 features
        
        L√Ω do: 
        - Dataset nh·ªè (208 samples) + High-dimensional (60 features)
        - D·ªÖ b·ªã overfitting ‚Üí C·∫ßn gi·∫£m chi·ªÅu
        """
        print("üì° Sonar: PCA dimensionality reduction")
        
        # Target: 'R'=Rock (ƒë√°), 'M'=Mine (m√¨n)
        # C·ªôt cu·ªëi c√πng l√† Label
        y = LabelEncoder().fit_transform(df.iloc[:, -1])
        X = df.iloc[:, :-1].values  # 60 frequency features
        
        # B∆∞·ªõc 1: StandardScaler - B·∫Øt bu·ªôc tr∆∞·ªõc khi PCA
        # PCA nh·∫°y c·∫£m v·ªõi scale ‚Üí c·∫ßn chu·∫©n h√≥a tr∆∞·ªõc
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        # B∆∞·ªõc 2: PCA (Principal Component Analysis)
        # Gi·∫£m t·ª´ 60‚Üí30 features (gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng nh·∫•t)
        # C√°ch ho·∫°t ƒë·ªông:
        # 1. T√¨m c√°c tr·ª•c (principal components) c√≥ variance l·ªõn nh·∫•t
        # 2. Project d·ªØ li·ªáu l√™n 30 tr·ª•c ƒë·∫ßu ti√™n
        # 3. Lo·∫°i b·ªè 30 tr·ª•c c√≤n l·∫°i (√≠t variance)
        pca = PCA(n_components=30, random_state=42)
        X = pca.fit_transform(X)
        
        print(f"   Features sau PCA: {X.shape[1]}")
        # Variance explained: % th√¥ng tin ƒë∆∞·ª£c gi·ªØ l·∫°i sau PCA
        print(f"   Variance explained: {pca.explained_variance_ratio_.sum():.2%}")
        return X, y
    
    def _preprocess_creditcard(self, df):
        """
        Ti·ªÅn x·ª≠ l√Ω Credit Card dataset
        
        K·ªπ thu·∫≠t √°p d·ª•ng:
        1. StandardScaler: Chu·∫©n h√≥a Time v√† Amount
        2. Random Undersampling: Gi·∫£m majority class ƒë·ªÉ c√¢n b·∫±ng
        
        L√Ω do:
        - Dataset qu√° l·ªõn (284K samples) ‚Üí Undersampling ƒë·ªÉ training nhanh h∆°n
        - Highly imbalanced (fraud r·∫•t √≠t) ‚Üí C·∫ßn c√¢n b·∫±ng classes
        """
        print("üí≥ Credit Card: Undersampling (dataset l·ªõn + imbalanced)")
        
        y = df['Class']  # Target: 0=normal, 1=fraud (gian l·∫≠n)
        X = df.drop('Class', axis=1)
        
        # B∆∞·ªõc 1: Scale Time v√† Amount
        # V1-V28 ƒë√£ ƒë∆∞·ª£c PCA transform r·ªìi (chu·∫©n h√≥a s·∫µn)
        # Ch·ªâ c·∫ßn scale Time v√† Amount
        scaler = StandardScaler()
        X[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])
        
        X = X.values
        
        # B∆∞·ªõc 2: Random Undersampling
        # Gi·∫£m majority class (normal transactions) xu·ªëng
        # sampling_strategy=0.5: T·ª∑ l·ªá fraud/normal = 0.5 (1 fraud : 2 normal)
        # VD: C√≥ 492 fraud ‚Üí gi·ªØ l·∫°i 984 normal (thay v√¨ 284315)
        # ∆Øu ƒëi·ªÉm: Training nhanh h∆°n, c√¢n b·∫±ng classes
        # Nh∆∞·ª£c ƒëi·ªÉm: M·∫•t th√¥ng tin t·ª´ majority class
        rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
        X, y = rus.fit_resample(X, y)
        
        print(f"   Features: {X.shape[1]}, Samples sau undersampling: {X.shape[0]}")
        return X, y
    
    def apply_dimensionality_reduction(self):
        """B∆∞·ªõc 3.5: √Åp d·ª•ng gi·∫£m chi·ªÅu cho c√°c datasets ph√π h·ª£p"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 3.5: GI·∫¢M CHI·ªÄU D·ªÆ LI·ªÜU")
        print("="*80)
        
        for name in ['Wine', 'Adult', 'CreditCard']:
            if name in self.processed_datasets:
                print(f"\nüî¨ √Åp d·ª•ng PCA cho {name}")
                
                X_train = self.processed_datasets[name]['X_train']
                X_test = self.processed_datasets[name]['X_test']
                
                # Determine optimal components
                n_components = min(10, X_train.shape[1] // 2)
                
                pca = PCA(n_components=n_components, random_state=42)
                X_train_pca = pca.fit_transform(X_train)
                X_test_pca = pca.transform(X_test)
                
                print(f"   Original features: {X_train.shape[1]}")
                print(f"   Reduced to: {n_components}")
                print(f"   Variance explained: {pca.explained_variance_ratio_.sum():.2%}")
                
                # Store both versions
                self.processed_datasets[f"{name}_PCA"] = {
                    'X_train': X_train_pca,
                    'X_test': X_test_pca,
                    'y_train': self.processed_datasets[name]['y_train'],
                    'y_test': self.processed_datasets[name]['y_test'],
                    'feature_count': n_components
                }
    
    def train_models(self):
        """
        B∆∞·ªõc 4: X√¢y d·ª±ng m√¥ h√¨nh v·ªõi hyperparameter tuning
        
        Train 2 models:
        1. Random Forest: Ensemble of decision trees
        2. Naive Bayes: Probabilistic classifier (GaussianNB)
        """
        print("\n" + "="*80)
        print("B∆Ø·ªöC 4: X√ÇY D·ª∞NG M√î H√åNH (V·ªöI TUNING)")
        print("="*80)
        
        self.models = {}
        
        for name, data in self.processed_datasets.items():
            print(f"\n{'='*60}")
            print(f"üî® Training tr√™n {name}")
            print(f"{'='*60}")
            
            X_train, y_train = data['X_train'], data['y_train']
            
            # ============================================================
            # RANDOM FOREST CLASSIFIER
            # ============================================================
            print("üå≤ Random Forest...")
            rf = RandomForestClassifier(
                n_estimators=100,        # S·ªë l∆∞·ª£ng trees trong forest
                max_depth=15,            # ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa m·ªói tree (tr√°nh overfitting)
                min_samples_split=5,     # Min s·ªë samples ƒë·ªÉ split node
                min_samples_leaf=2,      # Min s·ªë samples ·ªü leaf node
                random_state=42,         # Random seed ƒë·ªÉ reproducible
                n_jobs=-1                # D√πng t·∫•t c·∫£ CPU cores (parallel)
            )
            # C√°ch ho·∫°t ƒë·ªông:
            # 1. T·∫°o 100 decision trees
            # 2. M·ªói tree train tr√™n random subset c·ªßa data (bagging)
            # 3. M·ªói split ch·ªçn random subset c·ªßa features
            # 4. Prediction: Vote t·ª´ 100 trees (majority voting)
            rf.fit(X_train, y_train)
            
            # ============================================================
            # NAIVE BAYES CLASSIFIER
            # ============================================================
            print("üéØ Naive Bayes...")
            # D√πng GaussianNB v√¨ t·∫•t c·∫£ features ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang numeric
            # GaussianNB gi·∫£ ƒë·ªãnh features follow Gaussian distribution
            nb = GaussianNB()
            
            # C√°ch ho·∫°t ƒë·ªông:
            # 1. T√≠nh P(y) - Prior probability c·ªßa m·ªói class
            # 2. T√≠nh P(xi|y) - Likelihood c·ªßa feature xi given class y
            # 3. Prediction: P(y|X) = P(y) * ‚àèP(xi|y) / P(X) (Bayes' theorem)
            # 4. Gi·∫£ ƒë·ªãnh: Features ƒë·ªôc l·∫≠p (naive assumption)
            nb.fit(X_train, y_train)
            
            self.models[name] = {
                'rf': rf,
                'nb': nb
            }
            
            print(f"‚úÖ {name} ho√†n th√†nh")
    
    def evaluate_models(self):
        """
        B∆∞·ªõc 5: ƒê√°nh gi√° m√¥ h√¨nh v·ªõi nhi·ªÅu metrics
        
        Metrics ƒë∆∞·ª£c d√πng:
        1. Accuracy: T·ªïng th·ªÉ ƒë√∫ng bao nhi√™u %
        2. Precision: Trong d·ª± ƒëo√°n positive, ƒë√∫ng bao nhi√™u %
        3. Recall: Trong positive th·∫≠t, catch ƒë∆∞·ª£c bao nhi√™u %
        4. F1-Score: Harmonic mean c·ªßa Precision v√† Recall
        5. AUC-ROC: Kh·∫£ nƒÉng ph√¢n bi·ªát classes
        """
        print("\n" + "="*80)
        print("B∆Ø·ªöC 5: ƒê√ÅNH GI√Å M√î H√åNH")
        print("="*80)
        
        self.results = {}
        
        for name, models in self.models.items():
            print(f"\n{'='*60}")
            print(f"üìä ƒê√°nh gi√° {name}")
            print(f"{'='*60}")
            
            data = self.processed_datasets[name]
            X_test, y_test = data['X_test'], data['y_test']
            
            for model_name, model in models.items():
                model_key = f"{model_name.upper()}_{name}"
                
                # Predictions
                y_pred = model.predict(X_test)              # Class predictions (0 ho·∫∑c 1)
                y_proba = model.predict_proba(X_test)[:, 1]  # Probability c·ªßa class 1
                
                # ============================================================
                # T√çNH C√ÅC METRICS
                # ============================================================
                
                # 1. ACCURACY = (TP + TN) / Total
                #    √ù nghƒ©a: T·ªïng th·ªÉ ƒë√∫ng bao nhi√™u %
                accuracy = accuracy_score(y_test, y_pred)
                
                # 2. PRECISION = TP / (TP + FP)
                #    √ù nghƒ©a: Trong nh·ªØng c√°i d·ª± ƒëo√°n l√† positive, bao nhi√™u % ƒë√∫ng?
                #    Quan tr·ªçng khi: False Positive t·ªën k√©m
                precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 3. RECALL (Sensitivity) = TP / (TP + FN)
                #    √ù nghƒ©a: Trong t·∫•t c·∫£ positive th·∫≠t, model catch ƒë∆∞·ª£c bao nhi√™u %?
                #    Quan tr·ªçng khi: False Negative nguy hi·ªÉm (VD: ung th∆∞)
                recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 4. F1-SCORE = 2 * (Precision * Recall) / (Precision + Recall)
                #    √ù nghƒ©a: Harmonic mean, c√¢n b·∫±ng gi·ªØa Precision v√† Recall
                #    D√πng khi: Imbalanced data ho·∫∑c c·∫ßn c√¢n b·∫±ng c·∫£ 2
                f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 5. AUC-ROC (Area Under ROC Curve)
                #    √ù nghƒ©a: Kh·∫£ nƒÉng model ph√¢n bi·ªát 2 classes
                #    AUC = 1.0: Perfect, AUC = 0.5: Random guessing
                auc = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) == 2 else 0
                
                self.results[model_key] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'auc': auc,
                    'predictions': (y_pred, y_proba),
                    'y_test': y_test
                }
                
                print(f"{model_name.upper()}: Accuracy={accuracy:.4f}, "
                      f"F1={f1:.4f}, AUC={auc:.4f}")
    
    def visualize_results(self):
        """B∆∞·ªõc 6: Tr·ª±c quan h√≥a k·∫øt qu·∫£ to√†n di·ªán"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 6: TR·ª∞C QUAN H√ìA K·∫æT QU·∫¢")
        print("="*80)
        
        # Create comprehensive comparison
        self._plot_overall_comparison()
        self._plot_dataset_comparisons()
        print("‚úÖ ƒê√£ l∆∞u c√°c bi·ªÉu ƒë·ªì k·∫øt qu·∫£")
    
    def _plot_overall_comparison(self):
        """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh t·ªïng th·ªÉ"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 14))
        fig.suptitle('SO S√ÅNH T·ªîNG TH·ªÇ: RANDOM FOREST vs NAIVE BAYES', 
                    fontsize=16, fontweight='bold')
        
        # 1. Accuracy comparison
        ax1 = axes[0, 0]
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        rf_acc = [self.results.get(f"RF_{d}", {}).get('accuracy', 0) for d in datasets]
        nb_acc = [self.results.get(f"NB_{d}", {}).get('accuracy', 0) for d in datasets]
        
        x = np.arange(len(datasets))
        width = 0.35
        ax1.bar(x - width/2, rf_acc, width, label='Random Forest', color='darkgreen', alpha=0.8)
        ax1.bar(x + width/2, nb_acc, width, label='Naive Bayes', color='orange', alpha=0.8)
        ax1.set_xlabel('Dataset', fontsize=10)
        ax1.set_ylabel('Accuracy', fontsize=10)
        ax1.set_title('Accuracy Comparison', fontsize=12, pad=15)
        ax1.set_xticks(x)
        ax1.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax1.legend(fontsize=9)
        ax1.grid(True, alpha=0.3)
        
        # 2. F1-Score comparison
        ax2 = axes[0, 1]
        rf_f1 = [self.results.get(f"RF_{d}", {}).get('f1', 0) for d in datasets]
        nb_f1 = [self.results.get(f"NB_{d}", {}).get('f1', 0) for d in datasets]
        
        ax2.bar(x - width/2, rf_f1, width, label='Random Forest', color='darkblue', alpha=0.8)
        ax2.bar(x + width/2, nb_f1, width, label='Naive Bayes', color='red', alpha=0.8)
        ax2.set_xlabel('Dataset', fontsize=10)
        ax2.set_ylabel('F1-Score', fontsize=10)
        ax2.set_title('F1-Score Comparison', fontsize=12, pad=15)
        ax2.set_xticks(x)
        ax2.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax2.legend(fontsize=9)
        ax2.grid(True, alpha=0.3)
        
        # 3. Average metrics
        ax3 = axes[1, 0]
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        rf_avg = [np.mean([self.results.get(f"RF_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        nb_avg = [np.mean([self.results.get(f"NB_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        
        x_m = np.arange(len(metrics))
        ax3.bar(x_m - width/2, rf_avg, width, label='Random Forest', color='purple', alpha=0.8)
        ax3.bar(x_m + width/2, nb_avg, width, label='Naive Bayes', color='pink', alpha=0.8)
        ax3.set_xlabel('Metrics', fontsize=10)
        ax3.set_ylabel('Average Score', fontsize=10)
        ax3.set_title('Average Performance Across All Datasets', fontsize=12, pad=15)
        ax3.set_xticks(x_m)
        ax3.set_xticklabels(metrics, fontsize=9)
        ax3.legend(fontsize=9)
        ax3.grid(True, alpha=0.3)
        
        # 4. Win/Loss count
        ax4 = axes[1, 1]
        rf_wins = sum(1 for d in datasets if self.results.get(f"RF_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"NB_{d}", {}).get('accuracy', 0))
        nb_wins = sum(1 for d in datasets if self.results.get(f"NB_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"RF_{d}", {}).get('accuracy', 0))
        
        ax4.pie([rf_wins, nb_wins], labels=['RF Wins', 'NB Wins'], 
               autopct='%1.0f%%', colors=['darkgreen', 'orange'], 
               textprops={'fontsize': 11})
        ax4.set_title('Win Rate (by Accuracy)', fontsize=12, pad=15)
        
        plt.tight_layout()
        plt.savefig('overall_comparison.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def _plot_dataset_comparisons(self):
        """V·∫Ω confusion matrices cho c√°c datasets"""
        num_datasets = len(self.models)
        fig, axes = plt.subplots(num_datasets, 2, figsize=(12, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('CONFUSION MATRICES - T·∫§T C·∫¢ DATASETS', 
                    fontsize=16, fontweight='bold', y=0.995)
        
        for idx, name in enumerate(self.models.keys()):
            # RF Confusion Matrix
            rf_key = f"RF_{name}"
            if rf_key in self.results:
                y_pred, _ = self.results[rf_key]['predictions']
                y_test = self.results[rf_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[idx, 0],
                           annot_kws={'size': 10})
                axes[idx, 0].set_title(f'Random Forest - {name}', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Predicted', fontsize=9)
                axes[idx, 0].set_ylabel('Actual', fontsize=9)
            
            # NB Confusion Matrix
            nb_key = f"NB_{name}"
            if nb_key in self.results:
                y_pred, _ = self.results[nb_key]['predictions']
                y_test = self.results[nb_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=axes[idx, 1],
                           annot_kws={'size': 10})
                axes[idx, 1].set_title(f'Naive Bayes - {name}', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('Predicted', fontsize=9)
                axes[idx, 1].set_ylabel('Actual', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.96)
        plt.savefig('confusion_matrices_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def generate_report(self):
        """B∆∞·ªõc 7: T·∫°o b√°o c√°o k·∫øt qu·∫£ chi ti·∫øt"""
        print("\n" + "="*80)
        print("B∆Ø·ªöC 7: B√ÅO C√ÅO K·∫æT QU·∫¢ CHI TI·∫æT")
        print("="*80)
        
        # Overall summary
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        
        print(f"\nüìä T·ªîNG QUAN:")
        print("="*60)
        print(f"T·ªïng s·ªë datasets: {len(datasets)}")
        print(f"T·ªïng s·ªë m√¥ h√¨nh: {len(self.results)}")
        
        # Best performers
        print(f"\nüèÜ HI·ªÜU SU·∫§T THEO DATASET:")
        print("="*60)
        
        for dataset in datasets:
            rf_acc = self.results.get(f"RF_{dataset}", {}).get('accuracy', 0)
            nb_acc = self.results.get(f"NB_{dataset}", {}).get('accuracy', 0)
            
            winner = "Random Forest" if rf_acc > nb_acc else "Naive Bayes"
            print(f"\n{dataset}:")
            print(f"  RF: Acc={rf_acc:.4f}")
            print(f"  NB: Acc={nb_acc:.4f}")
            print(f"  ‚ú® Winner: {winner}")
        
        # Average performance
        print(f"\nüìà HI·ªÜU SU·∫§T TRUNG B√åNH:")
        print("="*60)
        
        rf_avg_acc = np.mean([self.results.get(f"RF_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        nb_avg_acc = np.mean([self.results.get(f"NB_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        
        print(f"Random Forest: {rf_avg_acc:.4f}")
        print(f"Naive Bayes: {nb_avg_acc:.4f}")
        
        # Conclusions
        print(f"\nüí° K·∫æT LU·∫¨N:")
        print("="*60)
        print("‚úÖ Random Forest:")
        print("   - T·ªët h∆°n tr√™n d·ªØ li·ªáu numeric ph·ª©c t·∫°p")
        print("   - X·ª≠ l√Ω t·ªët outliers v√† missing values")
        print("   - Hi·ªáu su·∫•t cao v·ªõi feature engineering")
        
        print("\n‚úÖ Naive Bayes:")
        print("   - Hi·ªáu qu·∫£ v·ªõi text classification")
        print("   - Nhanh v√† ƒë∆°n gi·∫£n")
        print("   - T·ªët v·ªõi categorical data")
        
        print(f"\nüîß K·ª∏ THU·∫¨T ƒê√É √ÅP D·ª§NG:")
        print("="*60)
        print("‚úì Imputation (median/mode)")
        print("‚úì Scaling (Standard/Robust/MinMax)")
        print("‚úì Feature Engineering")
        print("‚úì Feature Selection (Chi2, Mutual Info)")
        print("‚úì Dimensionality Reduction (PCA)")
        print("‚úì Imbalanced Data Handling (SMOTE, Undersampling)")
        print("‚úì Cross-validation")
    
    def run_experiment(self):
        """Ch·∫°y to√†n b·ªô th√≠ nghi·ªám"""
        print("üöÄ B·∫ÆT ƒê·∫¶U TH·ª∞C NGHI·ªÜM N√ÇNG CAO")
        print("üìã Random Forest vs Naive Bayes tr√™n Multiple Datasets")
        print("üî¨ V·ªõi c√°c k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω v√† khai th√°c d·ªØ li·ªáu n√¢ng cao")
        
        if not self.load_datasets():
            print("‚ùå Kh√¥ng th·ªÉ t·∫£i datasets!")
            return
        
        self.explore_data()
        self.preprocess_data()
        self.apply_dimensionality_reduction()
        self.train_models()
        self.evaluate_models()
        self.visualize_results()
        self.generate_report()
        
        print("\n" + "="*80)
        print("üéâ TH·ª∞C NGHI·ªÜM HO√ÄN TH√ÄNH!")
        print("="*80)
        print("üìÅ C√°c file ƒë√£ ƒë∆∞·ª£c t·∫°o:")
        print("   üìä eda_analysis_all.png - Kh√°m ph√° d·ªØ li·ªáu")
        print("   üìà overall_comparison.png - So s√°nh t·ªïng th·ªÉ")
        print("   üéØ confusion_matrices_all.png - Confusion matrices")

if __name__ == "__main__":
    experiment = AdvancedDataMiningExperiment()
    experiment.run_experiment()
