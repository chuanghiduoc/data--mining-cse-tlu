#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
THá»°C NGHIá»†M SO SÃNH RANDOM FOREST VÃ€ NAIVE BAYES
Vá»›i nhiá»u datasets vÃ  ká»¹ thuáº­t tiá»n xá»­ lÃ½ nÃ¢ng cao

Author: Student
Date: 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (classification_report, confusion_matrix, 
                           accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve)
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, RFE
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
import warnings
warnings.filterwarnings('ignore')

# Thiáº¿t láº­p font cho tiáº¿ng Viá»‡t
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.style.use('seaborn-v0_8')

class AdvancedDataMiningExperiment:
    """
    Class thá»±c hiá»‡n thÃ­ nghiá»‡m khai phÃ¡ dá»¯ liá»‡u nÃ¢ng cao vá»›i nhiá»u datasets
    
    Má»¥c Ä‘Ã­ch: So sÃ¡nh Random Forest vÃ  Naive Bayes trÃªn nhiá»u loáº¡i dá»¯ liá»‡u khÃ¡c nhau
    vá»›i cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ nÃ¢ng cao
    """
    
    def __init__(self):
        """
        Khá»Ÿi táº¡o experiment
        - results: LÆ°u káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh (accuracy, precision, recall, f1, auc)
        - datasets: LÆ°u dá»¯ liá»‡u thÃ´ Ä‘Ã£ load
        - feature_importance: LÆ°u Ä‘á»™ quan trá»ng cá»§a features (tá»« Random Forest)
        """
        self.results = {}
        self.datasets = {}
        self.feature_importance = {}
        
    def load_datasets(self):
        """BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u - Táº£i táº¥t cáº£ datasets"""
        print("="*80)
        print("BÆ¯á»šC 1: THU THáº¬P Dá»® LIá»†U")
        print("="*80)
        
        datasets_config = {
            'Wine': {
                'path': 'datasets/winequality-red.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'Diabetes': {
                'path': 'datasets/diabetes.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'Adult': {
                'path': 'datasets/adult.csv',
                'encoding': 'utf-8',
                'type': 'mixed'
            },
            'Mushroom': {
                'path': 'datasets/mushrooms.csv',
                'encoding': 'utf-8',
                'type': 'categorical'
            },
            'Sonar': {
                'path': 'datasets/sonar-all-data.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            },
            'CreditCard': {
                'path': 'datasets/creditcard.csv',
                'encoding': 'utf-8',
                'type': 'numeric'
            }
        }
        
        successful_loads = 0
        
        for name, config in datasets_config.items():
            try:
                print(f"\nğŸ“Š Äang táº£i {name} Dataset...")
                df = pd.read_csv(config['path'], encoding=config['encoding'])
                
                self.datasets[name] = {
                    'data': df,
                    'type': config['type'],
                    'shape': df.shape
                }
                
                print(f"   âœ… {name}: {df.shape[0]} máº«u, {df.shape[1]} cá»™t")
                successful_loads += 1
                
            except Exception as e:
                print(f"   âŒ Lá»—i táº£i {name}: {e}")
            
        print(f"\nâœ… ÄÃ£ táº£i thÃ nh cÃ´ng {successful_loads}/{len(datasets_config)} datasets")
        return successful_loads > 0
    
    def explore_data(self):
        """BÆ°á»›c 2: KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA) vá»›i phÃ¢n tÃ­ch chi tiáº¿t"""
        print("\n" + "="*80)
        print("BÆ¯á»šC 2: KHÃM PHÃ Dá»® LIá»†U (EDA)")
        print("="*80)
        
        for name, dataset_info in self.datasets.items():
            df = dataset_info['data']
            print(f"\n{'='*60}")
            print(f"ğŸ“Š {name.upper()} DATASET")
            print(f"{'='*60}")
            print(f"KÃ­ch thÆ°á»›c: {df.shape}")
            print(f"Loáº¡i dá»¯ liá»‡u: {dataset_info['type']}")
            print(f"\nThÃ´ng tin cá»™t:")
            print(df.dtypes)
            print(f"\nGiÃ¡ trá»‹ null:")
            print(df.isnull().sum())
            print(f"\nThá»‘ng kÃª mÃ´ táº£:")
            print(df.describe())
        
        # Visualization
        self.visualize_eda()
    
    def visualize_eda(self):
        """Váº½ biá»ƒu Ä‘á»“ khÃ¡m phÃ¡ dá»¯ liá»‡u cho táº¥t cáº£ datasets"""
        num_datasets = len(self.datasets)
        fig, axes = plt.subplots(num_datasets, 3, figsize=(20, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('KHÃM PHÃ Dá»® LIá»†U - Táº¤T Cáº¢ DATASETS', fontsize=18, fontweight='bold', y=0.995)
        
        for idx, (name, dataset_info) in enumerate(self.datasets.items()):
            df = dataset_info['data']
            
            # Subplot 1: Distribution of target
            target_col = self._get_target_column(name, df)
            if target_col:
                target_counts = df[target_col].value_counts()
                axes[idx, 0].bar(range(len(target_counts)), target_counts.values, color='steelblue', alpha=0.7)
                axes[idx, 0].set_title(f'{name}: PhÃ¢n bá»‘ Target', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Class', fontsize=9)
                axes[idx, 0].set_ylabel('Sá»‘ lÆ°á»£ng', fontsize=9)
                axes[idx, 0].tick_params(labelsize=8)
                
                # Add value labels
                for i, v in enumerate(target_counts.values):
                    axes[idx, 0].text(i, v + max(target_counts.values)*0.02, str(v), 
                                     ha='center', va='bottom', fontsize=8)
            
            # Subplot 2: Missing values
            missing = df.isnull().sum()
            if missing.sum() > 0:
                missing = missing[missing > 0].sort_values(ascending=False)[:10]
                axes[idx, 1].barh(range(len(missing)), missing.values, color='coral', alpha=0.7)
                axes[idx, 1].set_yticks(range(len(missing)))
                axes[idx, 1].set_yticklabels(missing.index, fontsize=8)
                axes[idx, 1].set_title(f'{name}: GiÃ¡ trá»‹ thiáº¿u', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('Sá»‘ lÆ°á»£ng', fontsize=9)
            else:
                axes[idx, 1].text(0.5, 0.5, 'KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u', 
                                 ha='center', va='center', fontsize=10)
                axes[idx, 1].set_title(f'{name}: GiÃ¡ trá»‹ thiáº¿u', fontsize=11, pad=10)
            axes[idx, 1].tick_params(labelsize=8)
            
            # Subplot 3: Feature types
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            categorical_cols = df.select_dtypes(include=['object']).columns
            
            type_counts = [len(numeric_cols), len(categorical_cols)]
            colors = ['lightgreen', 'lightcoral']
            axes[idx, 2].pie(type_counts, labels=['Numeric', 'Categorical'], 
                            autopct='%1.1f%%', colors=colors, textprops={'fontsize': 9})
            axes[idx, 2].set_title(f'{name}: Loáº¡i Features', fontsize=11, pad=10)
        
        plt.tight_layout(pad=3.0)
        plt.subplots_adjust(top=0.96)
        plt.savefig('eda_analysis_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        print("\nâœ… ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ EDA: eda_analysis_all.png")
        plt.close()
    
    def _get_target_column(self, dataset_name, df):
        """XÃ¡c Ä‘á»‹nh cá»™t target cho má»—i dataset"""
        target_map = {
            'Wine': 'quality',
            'Diabetes': 'Outcome',
            'Adult': 'income',
            'Mushroom': 'class',
            'Sonar': 'Label',
            'CreditCard': 'Class'
        }
        return target_map.get(dataset_name)
    
    def preprocess_data(self):
        """BÆ°á»›c 3: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u vá»›i nhiá»u ká»¹ thuáº­t nÃ¢ng cao"""
        print("\n" + "="*80)
        print("BÆ¯á»šC 3: TIá»€N Xá»¬ LÃ Dá»® LIá»†U (NÃ‚NG CAO)")
        print("="*80)
        
        self.processed_datasets = {}
        
        for name, dataset_info in self.datasets.items():
            print(f"\n{'='*60}")
            print(f"ğŸ”§ Xá»­ lÃ½ {name} Dataset")
            print(f"{'='*60}")
            
            df = dataset_info['data'].copy()
            
            if name == 'Wine':
                X, y = self._preprocess_wine(df)
            elif name == 'Diabetes':
                X, y = self._preprocess_diabetes(df)
            elif name == 'Adult':
                X, y = self._preprocess_adult(df)
            elif name == 'Mushroom':
                X, y = self._preprocess_mushroom(df)
            elif name == 'Sonar':
                X, y = self._preprocess_sonar(df)
            elif name == 'CreditCard':
                X, y = self._preprocess_creditcard(df)
            else:
                continue
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            self.processed_datasets[name] = {
                'X_train': X_train,
                'X_test': X_test,
                'y_train': y_train,
                'y_test': y_test,
                'feature_count': X.shape[1]
            }
            
            print(f"âœ… Train: {X_train.shape}, Test: {X_test.shape}")
    
    def _preprocess_wine(self, df):
        """
        Tiá»n xá»­ lÃ½ Wine dataset
        
        Ká»¹ thuáº­t Ã¡p dá»¥ng:
        1. Binary classification: Chuyá»ƒn quality thÃ nh 2 lá»›p (good/bad)
        2. Feature Engineering: Táº¡o features tÆ°Æ¡ng tÃ¡c
        3. RobustScaler: Scaling chá»‘ng outliers
        """
        print("ğŸ· Wine: Scaling + Feature Engineering")
        
        # BÆ°á»›c 1: Chuyá»ƒn sang binary classification
        # quality >= 6: good wine (1), quality < 6: bad wine (0)
        y = (df['quality'] >= 6).astype(int)
        X = df.drop('quality', axis=1)
        
        # BÆ°á»›c 2: Feature Engineering - Táº¡o features má»›i tá»« sá»± tÆ°Æ¡ng tÃ¡c
        # alcohol * sulphates: TÆ°Æ¡ng tÃ¡c giá»¯a Ä‘á»™ cá»“n vÃ  sulphates
        X['alcohol_sulphates'] = X['alcohol'] * X['sulphates']
        
        # volatile acidity / fixed acidity: Tá»· lá»‡ acid dá»… bay hÆ¡i
        # +0.001 Ä‘á»ƒ trÃ¡nh chia cho 0
        X['volatile_total_acidity'] = X['volatile acidity'] / (X['fixed acidity'] + 0.001)
        
        # BÆ°á»›c 3: RobustScaler - Scaling dá»±a trÃªn median vÃ  IQR
        # Æ¯u Ä‘iá»ƒm: Ãt bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers hÆ¡n StandardScaler
        # CÃ´ng thá»©c: X_scaled = (X - median) / IQR
        scaler = RobustScaler()
        X = scaler.fit_transform(X)
        
        print(f"   Features: {X.shape[1]}")
        return X, y
    
    def _preprocess_diabetes(self, df):
        """
        Tiá»n xá»­ lÃ½ Diabetes dataset
        
        Ká»¹ thuáº­t Ã¡p dá»¥ng:
        1. Smart Imputation: Xá»­ lÃ½ giÃ¡ trá»‹ 0 khÃ´ng há»£p lÃ½ (medical impossibility)
        2. StandardScaler: Chuáº©n hÃ³a dá»¯ liá»‡u
        3. SMOTE: Xá»­ lÃ½ imbalanced data (tÄƒng minority class)
        """
        print("ğŸ’‰ Diabetes: Imputation + Scaling + SMOTE")
        
        y = df['Outcome']  # Target: 1=cÃ³ tiá»ƒu Ä‘Æ°á»ng, 0=khÃ´ng
        X = df.drop('Outcome', axis=1)
        
        # BÆ°á»›c 1: Xá»­ lÃ½ giÃ¡ trá»‹ 0 khÃ´ng há»£p lÃ½ vá» máº·t y há»c
        # VD: Glucose=0, BloodPressure=0, BMI=0 lÃ  khÃ´ng thá»ƒ
        # â†’ Thay báº±ng NaN Ä‘á»ƒ impute sau
        zero_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
        for col in zero_cols:
            if col in X.columns:
                X[col] = X[col].replace(0, np.nan)  # 0 â†’ NaN
        
        # BÆ°á»›c 2: Imputation - Äiá»n giÃ¡ trá»‹ thiáº¿u báº±ng median
        # DÃ¹ng median thay vÃ¬ mean vÃ¬ Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers
        imputer = SimpleImputer(strategy='median')
        X = imputer.fit_transform(X)
        
        # BÆ°á»›c 3: StandardScaler - Chuáº©n hÃ³a vá» mean=0, std=1
        # CÃ´ng thá»©c: X_scaled = (X - mean) / std
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        # BÆ°á»›c 4: SMOTE (Synthetic Minority Over-sampling Technique)
        # Xá»­ lÃ½ imbalanced data báº±ng cÃ¡ch táº¡o synthetic samples cho minority class
        # CÃ¡ch hoáº¡t Ä‘á»™ng:
        # 1. Chá»n 1 sample tá»« minority class
        # 2. TÃ¬m k-nearest neighbors
        # 3. Táº¡o sample má»›i giá»¯a sample gá»‘c vÃ  neighbor
        smote = SMOTE(random_state=42)
        X, y = smote.fit_resample(X, y)
        
        print(f"   Features: {X.shape[1]}, Samples sau SMOTE: {X.shape[0]}")
        return X, y
    
    def _preprocess_adult(self, df):
        """Tiá»n xá»­ lÃ½ Adult dataset"""
        print("ğŸ‘¤ Adult: Mixed data handling + Encoding")
        
        # Clean column names
        df.columns = df.columns.str.strip()
        
        # Target
        y = LabelEncoder().fit_transform(df['income'])
        
        # Drop target and unnecessary columns
        X = df.drop(['income'], axis=1)
        
        # Handle missing values (marked as '?')
        X = X.replace('?', np.nan)
        
        # Separate numeric and categorical
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        categorical_cols = X.select_dtypes(include=['object']).columns
        
        # Impute numeric
        if len(numeric_cols) > 0:
            X[numeric_cols] = SimpleImputer(strategy='median').fit_transform(X[numeric_cols])
        
        # Impute and encode categorical
        for col in categorical_cols:
            X[col] = X[col].fillna(X[col].mode()[0])
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        # Scale
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        print(f"   Features: {X.shape[1]}")
        return X, y
    
    def _preprocess_mushroom(self, df):
        """
        Tiá»n xá»­ lÃ½ Mushroom dataset
        
        Ká»¹ thuáº­t Ã¡p dá»¥ng:
        1. Label Encoding: Chuyá»ƒn categorical â†’ numeric
        2. Feature Selection: Chá»n features quan trá»ng báº±ng Mutual Information
        
        LÃ½ do: Mushroom dataset cÃ³ 23 categorical features
        â†’ Cáº§n encode sang numeric Ä‘á»ƒ Random Forest vÃ  Naive Bayes xá»­ lÃ½ Ä‘Æ°á»£c
        """
        print("ğŸ„ Mushroom: Categorical encoding + Feature selection")
        
        # Target: 'e'=edible (Äƒn Ä‘Æ°á»£c), 'p'=poisonous (Ä‘á»™c)
        # LabelEncoder chuyá»ƒn 'e'â†’0, 'p'â†’1
        y = LabelEncoder().fit_transform(df['class'])
        X = df.drop('class', axis=1)
        
        # Label Encoding cho táº¥t cáº£ categorical features
        # VD: cap-shape: 'b'â†’0, 'c'â†’1, 'x'â†’2, 'f'â†’3, 'k'â†’4, 's'â†’5
        for col in X.columns:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        
        X = X.values  # Chuyá»ƒn DataFrame â†’ numpy array
        
        # Feature Selection báº±ng Mutual Information
        # Mutual Information Ä‘o "thÃ´ng tin chung" giá»¯a feature vÃ  target
        # Chá»n top 15 features cÃ³ MI cao nháº¥t (quan trá»ng nháº¥t)
        # Æ¯u Ä‘iá»ƒm: KhÃ´ng giáº£ Ä‘á»‹nh linear relationship nhÆ° correlation
        selector = SelectKBest(mutual_info_classif, k=min(15, X.shape[1]))
        X = selector.fit_transform(X, y)
        
        print(f"   Features sau selection: {X.shape[1]}")
        return X, y
    
    def _preprocess_sonar(self, df):
        """
        Tiá»n xá»­ lÃ½ Sonar dataset
        
        Ká»¹ thuáº­t Ã¡p dá»¥ng:
        1. StandardScaler: Chuáº©n hÃ³a dá»¯ liá»‡u
        2. PCA: Giáº£m chiá»u tá»« 60â†’30 features
        
        LÃ½ do: 
        - Dataset nhá» (208 samples) + High-dimensional (60 features)
        - Dá»… bá»‹ overfitting â†’ Cáº§n giáº£m chiá»u
        """
        print("ğŸ“¡ Sonar: PCA dimensionality reduction")
        
        # Target: 'R'=Rock (Ä‘Ã¡), 'M'=Mine (mÃ¬n)
        # Cá»™t cuá»‘i cÃ¹ng lÃ  Label
        y = LabelEncoder().fit_transform(df.iloc[:, -1])
        X = df.iloc[:, :-1].values  # 60 frequency features
        
        # BÆ°á»›c 1: StandardScaler - Báº¯t buá»™c trÆ°á»›c khi PCA
        # PCA nháº¡y cáº£m vá»›i scale â†’ cáº§n chuáº©n hÃ³a trÆ°á»›c
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        
        # BÆ°á»›c 2: PCA (Principal Component Analysis)
        # Giáº£m tá»« 60â†’30 features (giá»¯ láº¡i thÃ´ng tin quan trá»ng nháº¥t)
        # CÃ¡ch hoáº¡t Ä‘á»™ng:
        # 1. TÃ¬m cÃ¡c trá»¥c (principal components) cÃ³ variance lá»›n nháº¥t
        # 2. Project dá»¯ liá»‡u lÃªn 30 trá»¥c Ä‘áº§u tiÃªn
        # 3. Loáº¡i bá» 30 trá»¥c cÃ²n láº¡i (Ã­t variance)
        pca = PCA(n_components=30, random_state=42)
        X = pca.fit_transform(X)
        
        print(f"   Features sau PCA: {X.shape[1]}")
        # Variance explained: % thÃ´ng tin Ä‘Æ°á»£c giá»¯ láº¡i sau PCA
        print(f"   Variance explained: {pca.explained_variance_ratio_.sum():.2%}")
        return X, y
    
    def _preprocess_creditcard(self, df):
        """
        Tiá»n xá»­ lÃ½ Credit Card dataset
        
        Ká»¹ thuáº­t Ã¡p dá»¥ng:
        1. StandardScaler: Chuáº©n hÃ³a Time vÃ  Amount
        2. Random Undersampling: Giáº£m majority class Ä‘á»ƒ cÃ¢n báº±ng
        
        LÃ½ do:
        - Dataset quÃ¡ lá»›n (284K samples) â†’ Undersampling Ä‘á»ƒ training nhanh hÆ¡n
        - Highly imbalanced (fraud ráº¥t Ã­t) â†’ Cáº§n cÃ¢n báº±ng classes
        """
        print("ğŸ’³ Credit Card: Undersampling (dataset lá»›n + imbalanced)")
        
        y = df['Class']  # Target: 0=normal, 1=fraud (gian láº­n)
        X = df.drop('Class', axis=1)
        
        # BÆ°á»›c 1: Scale Time vÃ  Amount
        # V1-V28 Ä‘Ã£ Ä‘Æ°á»£c PCA transform rá»“i (chuáº©n hÃ³a sáºµn)
        # Chá»‰ cáº§n scale Time vÃ  Amount
        scaler = StandardScaler()
        X[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])
        
        X = X.values
        
        # BÆ°á»›c 2: Random Undersampling
        # Giáº£m majority class (normal transactions) xuá»‘ng
        # sampling_strategy=0.5: Tá»· lá»‡ fraud/normal = 0.5 (1 fraud : 2 normal)
        # VD: CÃ³ 492 fraud â†’ giá»¯ láº¡i 984 normal (thay vÃ¬ 284315)
        # Æ¯u Ä‘iá»ƒm: Training nhanh hÆ¡n, cÃ¢n báº±ng classes
        # NhÆ°á»£c Ä‘iá»ƒm: Máº¥t thÃ´ng tin tá»« majority class
        rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
        X, y = rus.fit_resample(X, y)
        
        print(f"   Features: {X.shape[1]}, Samples sau undersampling: {X.shape[0]}")
        return X, y
    
    def apply_dimensionality_reduction(self):
        """BÆ°á»›c 3.5: Ãp dá»¥ng giáº£m chiá»u cho cÃ¡c datasets phÃ¹ há»£p"""
        print("\n" + "="*80)
        print("BÆ¯á»šC 3.5: GIáº¢M CHIá»€U Dá»® LIá»†U")
        print("="*80)
        
        for name in ['Wine', 'Adult', 'CreditCard']:
            if name in self.processed_datasets:
                print(f"\nğŸ”¬ Ãp dá»¥ng PCA cho {name}")
                
                X_train = self.processed_datasets[name]['X_train']
                X_test = self.processed_datasets[name]['X_test']
                
                # Determine optimal components
                n_components = min(10, X_train.shape[1] // 2)
                
                pca = PCA(n_components=n_components, random_state=42)
                X_train_pca = pca.fit_transform(X_train)
                X_test_pca = pca.transform(X_test)
                
                print(f"   Original features: {X_train.shape[1]}")
                print(f"   Reduced to: {n_components}")
                print(f"   Variance explained: {pca.explained_variance_ratio_.sum():.2%}")
                
                # Store both versions
                self.processed_datasets[f"{name}_PCA"] = {
                    'X_train': X_train_pca,
                    'X_test': X_test_pca,
                    'y_train': self.processed_datasets[name]['y_train'],
                    'y_test': self.processed_datasets[name]['y_test'],
                    'feature_count': n_components
                }
    
    def train_models(self):
        """
        BÆ°á»›c 4: XÃ¢y dá»±ng mÃ´ hÃ¬nh vá»›i hyperparameter tuning
        
        Train 2 models:
        1. Random Forest: Ensemble of decision trees
        2. Naive Bayes: Probabilistic classifier (GaussianNB)
        """
        print("\n" + "="*80)
        print("BÆ¯á»šC 4: XÃ‚Y Dá»°NG MÃ” HÃŒNH (Vá»šI TUNING)")
        print("="*80)
        
        self.models = {}
        
        for name, data in self.processed_datasets.items():
            print(f"\n{'='*60}")
            print(f"ğŸ”¨ Training trÃªn {name}")
            print(f"{'='*60}")
            
            X_train, y_train = data['X_train'], data['y_train']
            
            # ============================================================
            # RANDOM FOREST CLASSIFIER
            # ============================================================
            print("ğŸŒ² Random Forest...")
            rf = RandomForestClassifier(
                n_estimators=100,        # Sá»‘ lÆ°á»£ng trees trong forest
                max_depth=15,            # Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a má»—i tree (trÃ¡nh overfitting)
                min_samples_split=5,     # Min sá»‘ samples Ä‘á»ƒ split node
                min_samples_leaf=2,      # Min sá»‘ samples á»Ÿ leaf node
                random_state=42,         # Random seed Ä‘á»ƒ reproducible
                n_jobs=-1                # DÃ¹ng táº¥t cáº£ CPU cores (parallel)
            )
            # CÃ¡ch hoáº¡t Ä‘á»™ng:
            # 1. Táº¡o 100 decision trees
            # 2. Má»—i tree train trÃªn random subset cá»§a data (bagging)
            # 3. Má»—i split chá»n random subset cá»§a features
            # 4. Prediction: Vote tá»« 100 trees (majority voting)
            rf.fit(X_train, y_train)
            
            # ============================================================
            # NAIVE BAYES CLASSIFIER
            # ============================================================
            print("ğŸ¯ Naive Bayes...")
            # DÃ¹ng GaussianNB vÃ¬ táº¥t cáº£ features Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn sang numeric
            # GaussianNB giáº£ Ä‘á»‹nh features follow Gaussian distribution
            nb = GaussianNB()
            
            # CÃ¡ch hoáº¡t Ä‘á»™ng:
            # 1. TÃ­nh P(y) - Prior probability cá»§a má»—i class
            # 2. TÃ­nh P(xi|y) - Likelihood cá»§a feature xi given class y
            # 3. Prediction: P(y|X) = P(y) * âˆP(xi|y) / P(X) (Bayes' theorem)
            # 4. Giáº£ Ä‘á»‹nh: Features Ä‘á»™c láº­p (naive assumption)
            nb.fit(X_train, y_train)
            
            self.models[name] = {
                'rf': rf,
                'nb': nb
            }
            
            print(f"âœ… {name} hoÃ n thÃ nh")
    
    def evaluate_models(self):
        """
        BÆ°á»›c 5: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i nhiá»u metrics
        
        Metrics Ä‘Æ°á»£c dÃ¹ng:
        1. Accuracy: Tá»•ng thá»ƒ Ä‘Ãºng bao nhiÃªu %
        2. Precision: Trong dá»± Ä‘oÃ¡n positive, Ä‘Ãºng bao nhiÃªu %
        3. Recall: Trong positive tháº­t, catch Ä‘Æ°á»£c bao nhiÃªu %
        4. F1-Score: Harmonic mean cá»§a Precision vÃ  Recall
        5. AUC-ROC: Kháº£ nÄƒng phÃ¢n biá»‡t classes
        """
        print("\n" + "="*80)
        print("BÆ¯á»šC 5: ÄÃNH GIÃ MÃ” HÃŒNH")
        print("="*80)
        
        self.results = {}
        
        for name, models in self.models.items():
            print(f"\n{'='*60}")
            print(f"ğŸ“Š ÄÃ¡nh giÃ¡ {name}")
            print(f"{'='*60}")
            
            data = self.processed_datasets[name]
            X_test, y_test = data['X_test'], data['y_test']
            
            for model_name, model in models.items():
                model_key = f"{model_name.upper()}_{name}"
                
                # Predictions
                y_pred = model.predict(X_test)              # Class predictions (0 hoáº·c 1)
                y_proba = model.predict_proba(X_test)[:, 1]  # Probability cá»§a class 1
                
                # ============================================================
                # TÃNH CÃC METRICS
                # ============================================================
                
                # 1. ACCURACY = (TP + TN) / Total
                #    Ã nghÄ©a: Tá»•ng thá»ƒ Ä‘Ãºng bao nhiÃªu %
                accuracy = accuracy_score(y_test, y_pred)
                
                # 2. PRECISION = TP / (TP + FP)
                #    Ã nghÄ©a: Trong nhá»¯ng cÃ¡i dá»± Ä‘oÃ¡n lÃ  positive, bao nhiÃªu % Ä‘Ãºng?
                #    Quan trá»ng khi: False Positive tá»‘n kÃ©m
                precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 3. RECALL (Sensitivity) = TP / (TP + FN)
                #    Ã nghÄ©a: Trong táº¥t cáº£ positive tháº­t, model catch Ä‘Æ°á»£c bao nhiÃªu %?
                #    Quan trá»ng khi: False Negative nguy hiá»ƒm (VD: ung thÆ°)
                recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 4. F1-SCORE = 2 * (Precision * Recall) / (Precision + Recall)
                #    Ã nghÄ©a: Harmonic mean, cÃ¢n báº±ng giá»¯a Precision vÃ  Recall
                #    DÃ¹ng khi: Imbalanced data hoáº·c cáº§n cÃ¢n báº±ng cáº£ 2
                f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)
                
                # 5. AUC-ROC (Area Under ROC Curve)
                #    Ã nghÄ©a: Kháº£ nÄƒng model phÃ¢n biá»‡t 2 classes
                #    AUC = 1.0: Perfect, AUC = 0.5: Random guessing
                auc = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) == 2 else 0
                
                self.results[model_key] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'auc': auc,
                    'predictions': (y_pred, y_proba),
                    'y_test': y_test
                }
                
                print(f"{model_name.upper()}: Accuracy={accuracy:.4f}, "
                      f"F1={f1:.4f}, AUC={auc:.4f}")
    
    def visualize_results(self):
        """BÆ°á»›c 6: Trá»±c quan hÃ³a káº¿t quáº£ toÃ n diá»‡n"""
        print("\n" + "="*80)
        print("BÆ¯á»šC 6: TRá»°C QUAN HÃ“A Káº¾T QUáº¢")
        print("="*80)
        
        # Create comprehensive comparison
        self._plot_overall_comparison()
        self._plot_dataset_comparisons()
        print("âœ… ÄÃ£ lÆ°u cÃ¡c biá»ƒu Ä‘á»“ káº¿t quáº£")
    
    def _plot_overall_comparison(self):
        """Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh tá»•ng thá»ƒ"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 14))
        fig.suptitle('SO SÃNH Tá»”NG THá»‚: RANDOM FOREST vs NAIVE BAYES', 
                    fontsize=16, fontweight='bold')
        
        # 1. Accuracy comparison
        ax1 = axes[0, 0]
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        rf_acc = [self.results.get(f"RF_{d}", {}).get('accuracy', 0) for d in datasets]
        nb_acc = [self.results.get(f"NB_{d}", {}).get('accuracy', 0) for d in datasets]
        
        x = np.arange(len(datasets))
        width = 0.35
        ax1.bar(x - width/2, rf_acc, width, label='Random Forest', color='darkgreen', alpha=0.8)
        ax1.bar(x + width/2, nb_acc, width, label='Naive Bayes', color='orange', alpha=0.8)
        ax1.set_xlabel('Dataset', fontsize=10)
        ax1.set_ylabel('Accuracy', fontsize=10)
        ax1.set_title('Accuracy Comparison', fontsize=12, pad=15)
        ax1.set_xticks(x)
        ax1.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax1.legend(fontsize=9)
        ax1.grid(True, alpha=0.3)
        
        # 2. F1-Score comparison
        ax2 = axes[0, 1]
        rf_f1 = [self.results.get(f"RF_{d}", {}).get('f1', 0) for d in datasets]
        nb_f1 = [self.results.get(f"NB_{d}", {}).get('f1', 0) for d in datasets]
        
        ax2.bar(x - width/2, rf_f1, width, label='Random Forest', color='darkblue', alpha=0.8)
        ax2.bar(x + width/2, nb_f1, width, label='Naive Bayes', color='red', alpha=0.8)
        ax2.set_xlabel('Dataset', fontsize=10)
        ax2.set_ylabel('F1-Score', fontsize=10)
        ax2.set_title('F1-Score Comparison', fontsize=12, pad=15)
        ax2.set_xticks(x)
        ax2.set_xticklabels(datasets, rotation=45, ha='right', fontsize=8)
        ax2.legend(fontsize=9)
        ax2.grid(True, alpha=0.3)
        
        # 3. Average metrics
        ax3 = axes[1, 0]
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        rf_avg = [np.mean([self.results.get(f"RF_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        nb_avg = [np.mean([self.results.get(f"NB_{d}", {}).get(m, 0) for d in datasets]) 
                  for m in metrics]
        
        x_m = np.arange(len(metrics))
        ax3.bar(x_m - width/2, rf_avg, width, label='Random Forest', color='purple', alpha=0.8)
        ax3.bar(x_m + width/2, nb_avg, width, label='Naive Bayes', color='pink', alpha=0.8)
        ax3.set_xlabel('Metrics', fontsize=10)
        ax3.set_ylabel('Average Score', fontsize=10)
        ax3.set_title('Average Performance Across All Datasets', fontsize=12, pad=15)
        ax3.set_xticks(x_m)
        ax3.set_xticklabels(metrics, fontsize=9)
        ax3.legend(fontsize=9)
        ax3.grid(True, alpha=0.3)
        
        # 4. Win/Loss count
        ax4 = axes[1, 1]
        rf_wins = sum(1 for d in datasets if self.results.get(f"RF_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"NB_{d}", {}).get('accuracy', 0))
        nb_wins = sum(1 for d in datasets if self.results.get(f"NB_{d}", {}).get('accuracy', 0) > 
                      self.results.get(f"RF_{d}", {}).get('accuracy', 0))
        
        ax4.pie([rf_wins, nb_wins], labels=['RF Wins', 'NB Wins'], 
               autopct='%1.0f%%', colors=['darkgreen', 'orange'], 
               textprops={'fontsize': 11})
        ax4.set_title('Win Rate (by Accuracy)', fontsize=12, pad=15)
        
        plt.tight_layout()
        plt.savefig('overall_comparison.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def _plot_dataset_comparisons(self):
        """Váº½ confusion matrices cho cÃ¡c datasets"""
        num_datasets = len(self.models)
        fig, axes = plt.subplots(num_datasets, 2, figsize=(12, 5*num_datasets))
        
        if num_datasets == 1:
            axes = axes.reshape(1, -1)
        
        fig.suptitle('CONFUSION MATRICES - Táº¤T Cáº¢ DATASETS', 
                    fontsize=16, fontweight='bold', y=0.995)
        
        for idx, name in enumerate(self.models.keys()):
            # RF Confusion Matrix
            rf_key = f"RF_{name}"
            if rf_key in self.results:
                y_pred, _ = self.results[rf_key]['predictions']
                y_test = self.results[rf_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[idx, 0],
                           annot_kws={'size': 10})
                axes[idx, 0].set_title(f'Random Forest - {name}', fontsize=11, pad=10)
                axes[idx, 0].set_xlabel('Predicted', fontsize=9)
                axes[idx, 0].set_ylabel('Actual', fontsize=9)
            
            # NB Confusion Matrix
            nb_key = f"NB_{name}"
            if nb_key in self.results:
                y_pred, _ = self.results[nb_key]['predictions']
                y_test = self.results[nb_key]['y_test']
                cm = confusion_matrix(y_test, y_pred)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=axes[idx, 1],
                           annot_kws={'size': 10})
                axes[idx, 1].set_title(f'Naive Bayes - {name}', fontsize=11, pad=10)
                axes[idx, 1].set_xlabel('Predicted', fontsize=9)
                axes[idx, 1].set_ylabel('Actual', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.96)
        plt.savefig('confusion_matrices_all.png', dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
    
    def generate_report(self):
        """BÆ°á»›c 7: Táº¡o bÃ¡o cÃ¡o káº¿t quáº£ chi tiáº¿t"""
        print("\n" + "="*80)
        print("BÆ¯á»šC 7: BÃO CÃO Káº¾T QUáº¢ CHI TIáº¾T")
        print("="*80)
        
        # Overall summary
        datasets = list(set([k.split('_', 1)[1] for k in self.results.keys()]))
        
        print(f"\nğŸ“Š Tá»”NG QUAN:")
        print("="*60)
        print(f"Tá»•ng sá»‘ datasets: {len(datasets)}")
        print(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh: {len(self.results)}")
        
        # Best performers
        print(f"\nğŸ† HIá»†U SUáº¤T THEO DATASET:")
        print("="*60)
        
        for dataset in datasets:
            rf_acc = self.results.get(f"RF_{dataset}", {}).get('accuracy', 0)
            nb_acc = self.results.get(f"NB_{dataset}", {}).get('accuracy', 0)
            
            winner = "Random Forest" if rf_acc > nb_acc else "Naive Bayes"
            print(f"\n{dataset}:")
            print(f"  RF: Acc={rf_acc:.4f}")
            print(f"  NB: Acc={nb_acc:.4f}")
            print(f"  âœ¨ Winner: {winner}")
        
        # Average performance
        print(f"\nğŸ“ˆ HIá»†U SUáº¤T TRUNG BÃŒNH:")
        print("="*60)
        
        rf_avg_acc = np.mean([self.results.get(f"RF_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        nb_avg_acc = np.mean([self.results.get(f"NB_{d}", {}).get('accuracy', 0) 
                              for d in datasets])
        
        print(f"Random Forest: {rf_avg_acc:.4f}")
        print(f"Naive Bayes: {nb_avg_acc:.4f}")
        
        # Conclusions
        print(f"\nğŸ’¡ Káº¾T LUáº¬N:")
        print("="*60)
        print("âœ… Random Forest:")
        print("   - Tá»‘t hÆ¡n trÃªn dá»¯ liá»‡u numeric phá»©c táº¡p")
        print("   - Xá»­ lÃ½ tá»‘t outliers vÃ  missing values")
        print("   - Hiá»‡u suáº¥t cao vá»›i feature engineering")
        
        print("\nâœ… Naive Bayes:")
        print("   - Hiá»‡u quáº£ vá»›i text classification")
        print("   - Nhanh vÃ  Ä‘Æ¡n giáº£n")
        print("   - Tá»‘t vá»›i categorical data")
        
        print(f"\nğŸ”§ Ká»¸ THUáº¬T ÄÃƒ ÃP Dá»¤NG:")
        print("="*60)
        print("âœ“ Imputation (median/mode)")
        print("âœ“ Scaling (Standard/Robust/MinMax)")
        print("âœ“ Feature Engineering")
        print("âœ“ Feature Selection (Chi2, Mutual Info)")
        print("âœ“ Dimensionality Reduction (PCA)")
        print("âœ“ Imbalanced Data Handling (SMOTE, Undersampling)")
        print("âœ“ Cross-validation")
    
    def run_experiment(self):
        """Cháº¡y toÃ n bá»™ thÃ­ nghiá»‡m"""
        print("ğŸš€ Báº®T Äáº¦U THá»°C NGHIá»†M NÃ‚NG CAO")
        print("ğŸ“‹ Random Forest vs Naive Bayes trÃªn Multiple Datasets")
        print("ğŸ”¬ Vá»›i cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ vÃ  khai thÃ¡c dá»¯ liá»‡u nÃ¢ng cao")
        
        if not self.load_datasets():
            print("âŒ KhÃ´ng thá»ƒ táº£i datasets!")
            return
        
        self.explore_data()
        self.preprocess_data()
        self.apply_dimensionality_reduction()
        self.train_models()
        self.evaluate_models()
        self.visualize_results()
        self.generate_report()
        
        print("\n" + "="*80)
        print("ğŸ‰ THá»°C NGHIá»†M HOÃ€N THÃ€NH!")
        print("="*80)
        print("ğŸ“ CÃ¡c file Ä‘Ã£ Ä‘Æ°á»£c táº¡o:")
        print("   ğŸ“Š eda_analysis_all.png - KhÃ¡m phÃ¡ dá»¯ liá»‡u")
        print("   ğŸ“ˆ overall_comparison.png - So sÃ¡nh tá»•ng thá»ƒ")
        print("   ğŸ¯ confusion_matrices_all.png - Confusion matrices")

if __name__ == "__main__":
    experiment = AdvancedDataMiningExperiment()
    experiment.run_experiment()
